{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2024/ML2024_ex05notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex05notebookA\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## ロジスティック回帰＋勾配法によるパラメータの最適化 (3)\n",
        "----\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glgWbdlh34P"
      },
      "source": [
        "----\n",
        "### 準備\n",
        "\n",
        "\n",
        "以下，コードセルを上から順に実行してながら読んでいってね．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc  # アニメーションのため\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 最急降下法によるロジスティック回帰モデルの学習（2クラス識別の場合）\n",
        "\n",
        "2クラス識別のロジスティック回帰モデルで，パラメータを最急降下法で最適化する手順を考えましょう．\n",
        "\n",
        "2クラス識別のロジスティック回帰の問題設定は以下の通りでした．"
      ],
      "metadata": {
        "id": "szdqM433mzUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**［ロジスティック回帰の問題設定（2クラスの場合）］**\n",
        "\n",
        "$D$次元のデータを二つのクラスに識別するモデルを学習させる．学習データは $N$ 個あり，次のように与えられる．\n",
        "\n",
        "$$\n",
        "(\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2),\\ldots , (\\mathbf{x}_N, y_N)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "ただし，$\\mathbf{x}_n \\in {\\cal R}^{D}$ はモデルへの入力であり，$y_n \\in \\{0, 1\\}$ はこのデータの所属クラスの正解を表す値である（$n=1,2,\\ldots,N$）．\n",
        "\n",
        "学習モデルは次式で定める．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "f(\\mathbf{x}) &= \\sigma\\left( w_0 + \\sum_{d=1}^{D}w_dx_d \\right) \\\\\n",
        " &= \\frac{1}{\\displaystyle 1+\\exp{\\left( - \\left( w_0 + \\sum_{d=1}^{D}w_dx_d \\right) \\right)}} \\qquad (1)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "ここで， $\\sigma(s)$ はシグモイド関数 $\\sigma(s) = \\frac{1}{1+e^{-s}}$ を表す．\n",
        "このモデルのパラメータは $w_0, w_1, \\ldots, w_D$ の $(D+1)$ 個ある．\n",
        "\n",
        "このとき，モデルの出力と正解の値との間の「遠さ」を，次式の交差エントロピーで定義する．\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H &= -\\sum_{n=1}^{N} \\left( y_n\\log{f(\\mathbf{x}_n})+(1-y_n)\\log{\\left( 1-f(\\mathbf{x}_n)\\right)} \\right) \\qquad (2)\n",
        "\\end{aligned}\n",
        "$$\n",
        "この $H$ の値がなるべく小さくなるようにパラメータ $w_0, w_1, \\ldots, w_D$ を求めたい．"
      ],
      "metadata": {
        "id": "H23SZSZ_nK-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "パラメータをならべたベクトルを $\\mathbf{w} = (w_0, w_1, \\ldots, w_D)$ と表すことにして，$H$ を最小にする $\\mathbf{w}$ を求める最急降下法の手続きを導出します．"
      ],
      "metadata": {
        "id": "wbpaIS08cdoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 勾配の計算\n",
        "\n",
        "最急降下法では $H$ の $\\mathbf{w}$ に関する勾配\n",
        "$$\n",
        "\\nabla{H} = \\left( \\frac{\\partial H}{\\partial w_0}, \\frac{\\partial H}{\\partial w_1}, \\ldots, \\frac{\\partial H}{\\partial w_D}\\right)\n",
        "$$\n",
        "が必要ですので，$\\frac{\\partial H}{\\partial w_d}$ ($d=0,1,\\ldots,D$) を求めましょう．"
      ],
      "metadata": {
        "id": "zDEYO9tdnSXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず，\n",
        "\n",
        "$$\n",
        "\\ell_n = y_n\\log f(\\mathbf{x}_n) + (1-y_n)\\log(1-f(\\mathbf{x}_n)) \\qquad (3)\\\\\n",
        "$$\n",
        "\n",
        "とおくことにします．このとき，\n",
        "\n",
        "$$\n",
        "\\frac{\\partial H}{\\partial w_d} = -\\sum_{n=1}^{N}\\frac{\\partial \\ell_n}{\\partial w_d} \\qquad (4)\n",
        "$$\n",
        "\n",
        "です． $\\frac{\\partial \\ell_n}{\\partial w_d}$ を計算すると\n",
        "\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\ell_n}{\\partial w_d} = \\left(y_n-f(\\mathbf{x}_n)\\right)x_{n,d} \\qquad (n = 1, 2, \\ldots, N, d = 0, 1, \\ldots, D) \\qquad (5)\n",
        "$$\n",
        "\n",
        "が得られます（notebookC参照）．ただし，$x_{n,0} \\equiv 1$ としました．\n",
        "\n"
      ],
      "metadata": {
        "id": "iEV-N3WdeO1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上より，勾配ベクトルの要素は\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial H}{\\partial w_d} &= -\\sum_{n=1}^{N}\\frac{\\partial \\ell_n}{\\partial w_d} = -\\sum_{n}^{N}(y_n - f(\\mathbf{x}_n))x_{n,d}\\qquad (d = 0, 1, \\ldots, D) \\qquad (6)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "となります．ベクトルの形にまとめると，\n",
        "\n",
        "$$\n",
        "\\nabla{H} =  -\\sum_{n}^{N}(y_n - f(\\mathbf{x}_n)) \\mathbf{x}_n \\qquad (7)\n",
        "$$\n",
        "\n",
        "と書けます．"
      ],
      "metadata": {
        "id": "vAN-rXfTrF3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### パラメータ更新式の導出\n",
        "\n",
        "勾配の式が求まりました．これを用いて最急降下法によるパラメータ更新式を求めると，次のようになります．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{w}^{\\rm new} &= \\mathbf{w} - \\eta \\nabla H \\\\\n",
        "&=\\mathbf{w} + \\eta\\sum_{n}^{N}(y_n - f(\\mathbf{x}_n)) \\mathbf{x}_n \\qquad (8)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$\\eta$ は正の定数（学習係数）です．\n",
        "\n",
        "交差エントロピーやシグモイドに $\\log$ や $\\exp$ が入っていたわりには，パラメータを更新するための式はシンプルな形になります．\n",
        "$f(\\mathbf{x}_n)$ はデータ $\\mathbf{x}_n$ をモデルに入力して得られる出力（$0 < f(\\mathbf{x}_n) < 1$），$y_n$ はその正解の値（$y_n \\in\\{0,1\\}$）でした．\n",
        "この式を見ると，両者の差 $y_n - f(\\mathbf{x}_n)$ と入力の値との積に応じてパラメータを更新することになっています．"
      ],
      "metadata": {
        "id": "obXGlYF4naBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 例: 2次元2クラスのデータのロジスティック回帰\n",
        "\n",
        "最急降下法のパラメータ更新式が求まりましたので，ロジスティック回帰モデルの学習手順をプログラムとして書くことができます．\n",
        "以前使ったのと同じ2次元2クラスのデータで実際にロジスティック回帰の学習を行ってみましょう．"
      ],
      "metadata": {
        "id": "GTOt0lzoni0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データの準備"
      ],
      "metadata": {
        "id": "JKWnQM7QpyHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 2次元正規分布で2クラスまたは3クラスのデータを生成する関数\n",
        "\n",
        "def getData(nclass=2, seed = None):\n",
        "\n",
        "    assert nclass == 2 or nclass == 3\n",
        "\n",
        "    if seed != None:\n",
        "        np.random.seed( seed )\n",
        "\n",
        "    # 2次元の spherical な正規分布3つからデータを生成\n",
        "    X0 = 1.0*np.random.randn(200, 2) + [3.0, 3.0]\n",
        "    X1 = 1.0*np.random.randn(200, 2) + [7.0, 6.0]\n",
        "    X2 = 0.5*np.random.randn(200, 2) + [3.0, 7.0]\n",
        "\n",
        "    # それらのラベル用のarray\n",
        "    lab0 = np.zeros(X0.shape[0], dtype = int)\n",
        "    lab1 = np.zeros(X1.shape[0], dtype = int) + 1\n",
        "    lab2 = np.zeros(X2.shape[0], dtype = int) + 2\n",
        "\n",
        "    # X （入力データ）, label （クラスラベル）, y（教師信号） をつくる\n",
        "    if nclass == 2:\n",
        "        X = np.vstack((X0, X1))\n",
        "        label = np.hstack((lab0, lab1))\n",
        "        y = np.zeros(X.shape[0])\n",
        "        y[label == 1] = 1.0\n",
        "    else:\n",
        "        X = np.vstack((X0, X1, X2))\n",
        "        label = np.hstack((lab0, lab1, lab2))\n",
        "        y = np.zeros((X.shape[0], nclass))\n",
        "        for ik in range(nclass):\n",
        "            y[label == ik, ik] = 1.0\n",
        "\n",
        "    return X, label, y"
      ],
      "metadata": {
        "id": "TWdplvkZoLwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの準備\n",
        "X2c, lab2c, y2c = getData(nclass=2, seed=0)\n",
        "N, D = X2c.shape\n",
        "X2c = np.vstack((np.ones(N), X2c.T)).T\n",
        "print(f'データ数 N = {N}, 次元数 D = {D}')\n",
        "\n",
        "fig = plt.figure(facecolor='white', figsize=(14, 6))\n",
        "\n",
        "# 左の2次元散布図\n",
        "ax0 = fig.add_subplot(121)\n",
        "ax0.set_xlim(0, 10)\n",
        "ax0.set_ylim(0, 10)\n",
        "ax0.set_aspect('equal')\n",
        "ax0.scatter(X2c[y2c == 0, 1], X2c[y2c == 0, 2]) # blue\n",
        "ax0.scatter(X2c[y2c == 1, 1], X2c[y2c == 1, 2]) # orange\n",
        "ax0.set_xlabel('$x_1$')\n",
        "ax0.set_ylabel('$x_2$')\n",
        "\n",
        "# 右の3次元散布図\n",
        "elevation = 20\n",
        "azimuth = -70\n",
        "ax1 = fig.add_subplot(122, projection='3d')\n",
        "ax1.scatter(X2c[y2c==0, 1], X2c[y2c==0, 2], 1) # blue\n",
        "ax1.scatter(X2c[y2c==1, 1], X2c[y2c==1, 2], 2) # orange\n",
        "ax1.set_xlim(0, 10)\n",
        "ax1.set_ylim(0, 10)\n",
        "ax1.view_init(elevation, azimuth)\n",
        "ax1.set_xlabel('$x_1$')\n",
        "ax1.set_ylabel('$x_2$')\n",
        "ax1.set_zlabel('$y$')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0epKdv_Iopv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習\n"
      ],
      "metadata": {
        "id": "2n9yYFPOojW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルは，学習のための関数の定義です．"
      ],
      "metadata": {
        "id": "_VswovwcvEh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル出力の計算\n",
        "def model2(X, w):\n",
        "    return 1.0 / (1.0 + np.exp(-(X @ w)))\n",
        "\n",
        "# 交差エントロピーと正解数\n",
        "def score2(yt, y):\n",
        "    ce = -np.sum(y*np.log(yt)+(1.0-y)*np.log(1.0-yt)) # 交差エントロピー\n",
        "    count = np.sum((yt >= 0.5)*y) + np.sum((yt < 0.5)*(1 - y)) # 正解数\n",
        "    return ce, count\n",
        "\n",
        "# 勾配の計算\n",
        "def grad2(X, yt, y):\n",
        "    return (yt - y) @ X"
      ],
      "metadata": {
        "id": "XM0mlpoYqMko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，上記の2次元2クラスデータのロジスティック回帰モデルの学習を行います．"
      ],
      "metadata": {
        "id": "3iaPoPFFvSJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの初期化\n",
        "w = (np.random.random(D+1) - 0.5) * 0.2 # [-0.1, 0.1) の一様乱数\n",
        "\n",
        "# 学習係数と学習繰り返し回数\n",
        "eta = 0.2/N\n",
        "nitr = 1000\n",
        "\n",
        "# 学習\n",
        "for i in range(nitr+1):\n",
        "    yt = model2(X2c, w)     # モデル出力の計算\n",
        "    ce, count = score2(yt, y2c) # 交差エントロピーと正解数の計算\n",
        "    dw = grad2(X2c, yt, y2c) # 勾配の計算\n",
        "    w -= eta * dw       # パラメータの更新\n",
        "    if (i < 100 and i % 10 == 0) or (i % 100 == 0):\n",
        "        print(f'{i}  {ce:.4f}  {float(count)/N}')"
      ],
      "metadata": {
        "id": "FlIx4N09qjES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "出力される数値は，左から順に「学習繰り返し回数」，「（学習データに対する）交差エントロピー」，「（同）識別率」です．最急降下法のステップを繰り返すごとに，交差エントロピーの値が減少していること，それに連れて識別率は上昇していることが分かります．"
      ],
      "metadata": {
        "id": "CGib2dqCvaWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習（アニメーション版）"
      ],
      "metadata": {
        "id": "1pP_FjFqvyYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルを実行すると，上記と同様の学習の過程をアニメーションに描きます．"
      ],
      "metadata": {
        "id": "uWqnfR-oy2o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの初期化\n",
        "w = (np.random.random(D+1) - 0.5) * 0.2 # [-0.1, 0.1) の一様乱数\n",
        "\n",
        "# 学習係数と学習繰り返し回数\n",
        "eta = 0.2/N\n",
        "nitr = 1000\n",
        "\n",
        "fig = plt.figure(facecolor='white', figsize=(12, 6))\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax2 = fig.add_subplot(122)\n",
        "elevation = 20\n",
        "azimuth = -70\n",
        "ax1.view_init(elevation, azimuth)\n",
        "ax1.set_xlim(0, 10)\n",
        "ax1.set_ylim(0, 10)\n",
        "ax1.set_zlim(0, 1)\n",
        "ax1.scatter(X2c[y2c==0, 1], X2c[y2c==0, 2], 0)\n",
        "ax1.scatter(X2c[y2c==1, 1], X2c[y2c==1, 2], 1)\n",
        "#fig.show()\n",
        "\n",
        "ax2.set_xlim(0, nitr)\n",
        "ax2.set_ylim(0, 300)\n",
        "\n",
        "aList = []\n",
        "xx, yy = np.meshgrid(np.linspace(0, 10, num=16), np.linspace(0, 10, num=16))\n",
        "xxr, yyr = xx.ravel(), yy.ravel()\n",
        "XX = np.vstack((np.ones(xxr.shape[0]), xxr, yyr)).T\n",
        "\n",
        "iList = []\n",
        "ceList = []\n",
        "\n",
        "for i in range(nitr+1):\n",
        "\n",
        "    yt = model2(X2c, w)     # モデル出力の計算\n",
        "    ce, count = score2(yt, y2c) # 交差エントロピーと正解数の計算\n",
        "    dw = grad2(X2c, yt, y2c) # 勾配の計算\n",
        "    w -= eta * dw       # パラメータの更新\n",
        "\n",
        "    if (i < 100 and i % 10 == 0) or i % 100 == 0:\n",
        "        iList.append(i)\n",
        "        ceList.append(ce)\n",
        "        ZZ = model2(XX, w)\n",
        "        zz = ZZ.reshape(xx.shape)\n",
        "        a1 = ax1.plot_wireframe(xx, yy, zz, color='green')\n",
        "        a2 = ax2.plot(iList, ceList, color='blue', marker='.')\n",
        "        rr = count/N*100\n",
        "        s = f'H = {ce:.3f}\\nrate = {rr:.1f}%'\n",
        "        a3 = ax2.text(500, 240, s, size=20)\n",
        "        aList.append([a1]+a2 + [a3])\n",
        "\n",
        "anim = animation.ArtistAnimation(fig, aList, interval=300)\n",
        "rc('animation', html='jshtml')\n",
        "plt.close()\n",
        "anim\n"
      ],
      "metadata": {
        "id": "mV8N4fqIwCiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルは実行するたびにパラメータが異なる乱数で初期化されます．何度かセルを実行して，どんな違いが出るか確認してみましょう．"
      ],
      "metadata": {
        "id": "2-prHLgJPCGz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ldLfpCk9DN"
      },
      "source": [
        "----\n",
        "### 一般のロジスティック回帰モデルとその学習\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまではクラス数が2の場合限定でロジスティック回帰の話をしてきました．ここからは，クラス数が3以上の問題でも使える一般のロジスティック回帰モデルとその学習について説明します．\n",
        "以下，クラス数を文字 $K$ で表します．"
      ],
      "metadata": {
        "id": "Ireyp8sG_wOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 一般のロジスティック回帰モデル"
      ],
      "metadata": {
        "id": "-24if-4xJzQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**［ロジスティック回帰の問題設定（$K$クラスの場合）］**\n",
        "\n",
        "$D$次元のデータを$K$個のクラスに識別するモデルを学習させる．学習データは $N$ 個あり，次のように与えられる．\n",
        "\n",
        "$$\n",
        "(\\mathbf{x}_1, \\mathbf{y}_1), (\\mathbf{x}_2, \\mathbf{y}_2),\\ldots , (\\mathbf{x}_N, \\mathbf{y}_N)\n",
        "$$\n",
        "\n",
        "ただし，$\\mathbf{x}_n \\in {\\cal R}^{D}$ はモデルへの入力である．また，$\\mathbf{y}_n \\in \\{0, 1\\}^{K}$ （$0$か$1$のみを要素にもつ$K$次元ベクトル）はこのデータの所属クラスの正解を表す値である（$n=1,2,\\ldots,N$）．\n",
        "\n",
        "$\\mathbf{y}_n = (y_{n,1}, y_{n,2}, \\ldots, y_{n,K})$ の要素 $y_{n,k}$ は，$n$番目の学習データが $k$ 番目のクラスに所属するならば $1$，さもなくば $1$ をとる．したがって，$\\mathbf{y}_n$ の要素はどれか一つだけが $1$ で他は全て $0$ である．\n",
        "\n",
        "学習モデルは次式で定める．\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{y}_k &= \\frac{\\exp s_k}{\\displaystyle\\sum_{k=1}^{K}\\exp{s_k}} \\qquad (k = 1, 2, \\ldots, K) \\qquad (10)\\\\\n",
        "s_k &= w_{k,0} + \\sum_{d=1}^{D}w_{k,d}x_d\n",
        "\\end{aligned}\n",
        "$$\n",
        "このモデルのパラメータは $w_{k,d}$ ($k = 1, 2, \\ldots, K, d = 0, 1, \\ldots, D$) の $K\\times (D+1)$ 個ある．\n",
        "\n",
        "このとき，モデルの出力と正解の値との間の「遠さ」を，次式の交差エントロピーで定義する．\n",
        "$$\n",
        "\\begin{aligned}\n",
        "H &= -\\sum_{n=1}^{N} \\sum_{k=1}^{K} y_{n,k}\\log{\\hat{y}_{n,k}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "この $H$ の値がなるべく小さくなるようにパラメータ $\\{ w_{k,d} \\}$ を求めたい．"
      ],
      "metadata": {
        "id": "U3WrawaFAS6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2クラス識別のロジスティック回帰モデルの出力は1つでしたが，一般化したロジスティック回帰モデルでは，$\\hat{y}_1,\\hat{y}_2,\\ldots, \\hat{y}_K$ と $K (=\\mbox{クラス数})$ 個あります．大雑把にいうと，2クラス識別のロジスティック回帰モデルを $K$ 個あわせたものになっています．\n",
        "\n",
        "ただし，2クラス識別では出力の値をシグモイド関数によって計算していたところが，こちらでは式(10)のようになっています．\n",
        "この式(10)は，**ソフトマックス関数**（**softmax**関数）と呼ばれるものです．\n",
        "式の形から明らかですが，$0 < \\hat{y}_k < 1$ および $\\sum_{k=1}^{K}\\hat{y}_k = 1$ となる性質があります．\n",
        "\n",
        "このことから，ある入力データに対するモデル出力 $\\hat{y}_1,\\hat{y}_2,\\ldots, \\hat{y}_K$ の値は，そのデータがそれぞれのクラスに所属する確信度合い（確率）を表すと解釈することができます．\n",
        "上記の交差エントロピーを最小化することで，正解クラスに対応する出力が $1$ に近づき，それ以外のクラスに対応する出力が $0$ に近づくようになります．"
      ],
      "metadata": {
        "id": "Zc5eUkHvFHWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 一般のロジスティック回帰モデルの学習"
      ],
      "metadata": {
        "id": "NolKoqHjJ57x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "導出過程は省略しますが，上記の交差エントロピのパラメータに関する勾配は次のようになります．\n",
        "\n",
        "$$\n",
        "\\frac{\\partial H}{\\partial w_{k,d}} =  -\\sum_{n}^{N}(y_{n,k} - \\hat{y}_{n,k}) x_{n,d} \\qquad(k = 1, 2, \\ldots, K, d = 0, 1, \\ldots, D)\n",
        "$$\n",
        "\n",
        "\n",
        "2クラスの場合と同じ構造をしていますね．\n",
        "\n",
        "以下，最急降下法の手順は2クラスの場合とほとんど同じですので，説明を省略します．"
      ],
      "metadata": {
        "id": "HmbNSAuSKgNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 例: 2次元3クラスのデータのロジスティック回帰\n",
        "\n",
        "2次元のデータを3クラスに識別する問題にロジスティック回帰を適用してみましょう．"
      ],
      "metadata": {
        "id": "i-Vj1TQ-hz2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データの準備"
      ],
      "metadata": {
        "id": "FfDeCgFaidLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの準備\n",
        "K = 3\n",
        "X3c, lab3c, Y3c = getData(nclass=K, seed=0)\n",
        "N, D = X3c.shape\n",
        "X3c = np.vstack((np.ones(N), X3c.T)).T\n",
        "print(f'データ数 N = {N}, 次元数 D = {D}')\n",
        "\n",
        "fig = plt.figure(facecolor='white', figsize=(14, 6))\n",
        "\n",
        "# 2次元散布図\n",
        "ax0 = fig.add_subplot(111)\n",
        "ax0.set_xlim(0, 10)\n",
        "ax0.set_ylim(0, 10)\n",
        "ax0.set_aspect('equal')\n",
        "ax0.scatter(X3c[lab3c == 0, 1], X3c[lab3c == 0, 2]) # blue\n",
        "ax0.scatter(X3c[lab3c == 1, 1], X3c[lab3c == 1, 2]) # orange\n",
        "ax0.scatter(X3c[lab3c == 2, 1], X3c[lab3c == 2, 2]) # green\n",
        "ax0.set_xlabel('$x_1$')\n",
        "ax0.set_ylabel('$x_2$')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2_yCYCNWiGFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習\n",
        "\n"
      ],
      "metadata": {
        "id": "S9NYeHngi0cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルは，学習のための関数の定義です．"
      ],
      "metadata": {
        "id": "BrRhVBwxIFOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル出力の計算\n",
        "def modelK(X, W):\n",
        "    s = np.exp(X @ W.T)\n",
        "    Yt = s / np.sum(s, axis=1)[:, np.newaxis]\n",
        "    return Yt\n",
        "\n",
        "# 交差エントロピーと正解数\n",
        "def scoreK(Y, Yt):\n",
        "    ce = -np.sum(Y * np.log(Yt))/len(Y)\n",
        "    count = np.sum(np.argmax(Y, axis=1) == np.argmax(Yt, axis=1))\n",
        "    return ce, count\n",
        "\n",
        "# 勾配の計算\n",
        "def gradK(X, Y, Yt):\n",
        "    return (Yt - Y).T @ X"
      ],
      "metadata": {
        "id": "pIcE4-2fi-eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，上記の2次元3クラスデータのロジスティック回帰モデルの学習を行います．"
      ],
      "metadata": {
        "id": "RkYQvVw-i-eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの初期化\n",
        "W = (np.random.random((K, D+1)) - 0.5) * 0.2 # [-0.1, 0.1) の一様乱数\n",
        "\n",
        "# 学習係数と学習繰り返し回数\n",
        "eta = 0.2/N\n",
        "nitr = 1000\n",
        "\n",
        "# 学習\n",
        "for i in range(nitr+1):\n",
        "    Yt = modelK(X3c, W)        # モデル出力の計算\n",
        "    ce, count = scoreK(Y3c, Yt) # 交差エントロピーと正解数の計算\n",
        "    dW = gradK(X3c, Y3c, Yt)   # 勾配の計算\n",
        "    W -= eta * dW              # パラメータの更新\n",
        "    if (i < 100 and i % 10 == 0) or (i % 100 == 0):\n",
        "        print(f'{i}  {ce:.4f}  {float(count)/N}')"
      ],
      "metadata": {
        "id": "mNTagLfLi-eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習を繰り返すにつれて交差エントロピーが減少し，学習データに対する正答率（正しく識別できたものの割合）が上昇していることが分かります．\n",
        "\n",
        "次のセルを実行すると，学習によって得られたモデルが2次元平面をどのように3つのクラスに分類しているかを可視化させることができます．"
      ],
      "metadata": {
        "id": "xm7sPXtRIcd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "xmin, xmax = 0, 10\n",
        "ymin, ymax = 0, 10\n",
        "npoints = 100\n",
        "dx, dy = (xmax - xmin)/npoints, (ymax - ymin)/npoints\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:dx, ymin:ymax:dy]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "\n",
        "# X_mesh の各点における事後確率の推定\n",
        "XX = X_mesh.reshape((-1, 2))\n",
        "XX = np.vstack((np.ones(len(XX)), XX.T)).T\n",
        "Yt = modelK(XX, W)\n",
        "pp = Yt.reshape((X_mesh.shape[0], X_mesh.shape[1], K))\n",
        "\n",
        "# グラフの描画\n",
        "fig, ax = plt.subplots()\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "for k in range(K):\n",
        "    ax.scatter(X3c[lab3c == k, 1], X3c[lab3c == k, 2])\n",
        "    ax.contourf(x_mesh, y_mesh, pp[:, :, k], levels=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(ymin, ymax)\n",
        "ax.set_aspect('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ed0wlbiWDinl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "図で3色に塗られた領域の色の濃さは，その位置に対応する値をモデルに入力したときのモデル出力のうち，その色に対応する値の大きさを表しています．上述のように，$K$個のモデル出力は，入力データがそれぞれのクラスに属する確率の推定値を表しています．\n",
        "図を見ると，学習データの点の多くが正しく塗り分けられていることが分かります．"
      ],
      "metadata": {
        "id": "iF5KpTdEKl21"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3er-CKximIlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
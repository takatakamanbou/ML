{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2023/ex14notebookC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex14notecookC\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2023)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "### 機械学習ライブラリ scikit-learn のいろいろ\n",
        "\n",
        "# 混合正規分布(Gaussian Mixture Model)モデル\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# ロジスティック回帰モデル\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# SVM（識別器）\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 階層型ニューラルネット（多層パーセプトロン）\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "Uba-rqwa906l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 密度推定と統計的パターン認識の実験\n",
        "---"
      ],
      "metadata": {
        "id": "te6_SrWg77No"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 手書き数字識別やってみる\n",
        "\n",
        "クラスごとのデータの分布を正規分布と仮定して事後確率を推定する方法で，手書き数字識別やってみましょう．\n"
      ],
      "metadata": {
        "id": "_-uFvg7i7wg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備"
      ],
      "metadata": {
        "id": "2lCGarMx8ji8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 手書き数字データの入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/minimnist.npz\n",
        "rv = np.load('minimnist.npz')\n",
        "datL = rv['datL'].astype(float)\n",
        "labL = rv['labL']\n",
        "datT = rv['datT'].astype(float)\n",
        "labT = rv['labT']\n",
        "print(datL.shape, labL.shape, datT.shape, labT.shape)\n",
        "\n",
        "K = 10 # クラス数\n",
        "D = datL.shape[1] # データの次元数 28 x 28 = 784"
      ],
      "metadata": {
        "id": "7_fawtR88nw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを画像として表示するための関数\n",
        "#\n",
        "def display(data, nx, ny, nrow=28, ncol=28, gap=4):\n",
        "\n",
        "    assert data.shape[0] == nx*ny\n",
        "    assert data.shape[1] == nrow*ncol\n",
        "\n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype = int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        for ix in range(nx):\n",
        "            ltx = ix*(ncol + gap) + gap\n",
        "            img[lty:lty+nrow, ltx:ltx+ncol] = data[iy*nx+ix].reshape((nrow, ncol))\n",
        "\n",
        "    # 画像の出力\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nKrwQ9C08q5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx, ny = 10, 5\n",
        "display(datL[:50], nx, ny)\n",
        "for iy in range(ny):\n",
        "    print(labL[iy*nx:(iy+1)*nx])"
      ],
      "metadata": {
        "id": "Sp8sRyQ88tTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XL = datL\n",
        "YL = labL\n",
        "NL, D = datL.shape\n",
        "K = 10"
      ],
      "metadata": {
        "id": "PWLaOEKaU4LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 事前確率を推定\n",
        "\n",
        "クラスごとの学習データの比率でクラス事前確率 $p(y)$ を推定．"
      ],
      "metadata": {
        "id": "PVR_pj5gWXTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py = np.empty(K)\n",
        "for k in range(K):\n",
        "    py[k] = np.sum(YL==k)/NL\n",
        "print('### 事前確率')\n",
        "print('p(y) = ', py)"
      ],
      "metadata": {
        "id": "T4bNsBjbWaO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 正規分布の当てはめ\n",
        "\n",
        "クラスごとのデータの分布 $p(\\mathbf{x}|y)$ を推定．\n",
        "多変量正規分布でモデル化し，それぞれの平均と分散共分散行列を求めます．"
      ],
      "metadata": {
        "id": "wNclsINHS_ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = np.empty(K, dtype=object)\n",
        "for k in range(K):\n",
        "    XX = XL[YL==k, :]\n",
        "    model[k] = GaussianMixture(n_components=1, covariance_type='full')\n",
        "    model[k].fit(XX)"
      ],
      "metadata": {
        "id": "Oa2JKSk0TaIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "クラスごとの正規分布の平均パラメータを可視化してみるとこんなん．"
      ],
      "metadata": {
        "id": "tXHupqZqVyjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xm = np.empty((K, D))\n",
        "for k in range(K):\n",
        "    xm[k, :] = model[k].means_[0, :]\n",
        "display(xm, K, 1)"
      ],
      "metadata": {
        "id": "kX9hBiE6V-Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 識別させてみる\n",
        "\n",
        "与えられたデータを事後確率の推定値が最大となるクラスへと分類する方法で，識別率を算出してみます．\n",
        "クラスごとのデータの平均をプロトタイプとする最短距離法でも同じことをやり，結果を比較します．前者を「方法1」，後者を「方法2」とします．"
      ],
      "metadata": {
        "id": "75iUO6brW4ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは学習データから．"
      ],
      "metadata": {
        "id": "61I3WT07YpoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = datL\n",
        "Y = labL\n",
        "N, _ = datL.shape\n",
        "\n",
        "score = np.empty(K)\n",
        "ncorrect1 = ncorrect2 = 0\n",
        "\n",
        "for n in range(N):\n",
        "    if n % 500 == 0:\n",
        "        print(f'{n}/{N}')\n",
        "    xx = X[n, :]\n",
        "\n",
        "    # 方法1: 事後確率の推定値が最大のクラスに識別\n",
        "    for k in range(K):\n",
        "        # log(p(y)p(x|y)) = log(p(y)) + log(p(x|y))\n",
        "        score[k] = np.log(py[k]) + model[k].score(xx[np.newaxis, :])\n",
        "    if np.argmax(score) == Y[n]:\n",
        "        ncorrect1 += 1\n",
        "\n",
        "    # 方法2: 最短距離法で識別\n",
        "    d2 = np.sum(np.square(xx[np.newaxis, :] - xm), axis=1)\n",
        "    if np.argmin(d2) == Y[n]:\n",
        "        ncorrect2 += 1\n",
        "\n",
        "print(f'方法1の識別率: {ncorrect1}/{N} = {ncorrect1/N:.3f}')\n",
        "print(f'方法2の識別率: {ncorrect2}/{N} = {ncorrect2/N:.3f}')"
      ],
      "metadata": {
        "id": "OH8sSt76X4Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ex14notebookA の「よだんだよん」に書いたことですが，最短距離法（方法2）は，方法1で正規分布モデルに強い制約を加えたものとみなすことができます．\n",
        "学習データの場合，そのような制約がなく $p(\\mathbf{x}|y)$ に任意の正規分布を当てはめられる方法1の方が高い識別率を示しています．\n"
      ],
      "metadata": {
        "id": "t7xoVUmEbjqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "では，テストデータではどうでしょう．"
      ],
      "metadata": {
        "id": "hXesrJg_aXs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = datT\n",
        "Y = labT\n",
        "N, _ = datT.shape\n",
        "\n",
        "score = np.empty(K)\n",
        "ncorrect1 = ncorrect2 = 0\n",
        "\n",
        "for n in range(N):\n",
        "    if n % 500 == 0:\n",
        "        print(f'{n}/{N}')\n",
        "    xx = X[n, :]\n",
        "\n",
        "    # 方法1: 事後確率の推定値が最大のクラスに識別\n",
        "    for k in range(K):\n",
        "        # log(p(y)p(x|y)) = log(p(y)) + log(p(x|y))\n",
        "        score[k] = np.log(py[k]) + model[k].score(xx[np.newaxis, :])\n",
        "    if np.argmax(score) == Y[n]:\n",
        "        ncorrect1 += 1\n",
        "\n",
        "    # 方法2: 最短距離法で識別\n",
        "    d2 = np.sum(np.square(xx[np.newaxis, :] - xm), axis=1)\n",
        "    if np.argmin(d2) == Y[n]:\n",
        "        ncorrect2 += 1\n",
        "\n",
        "print(f'方法1の識別率: {ncorrect1}/{N} = {ncorrect1/N:.3f}')\n",
        "print(f'方法2の識別率: {ncorrect2}/{N} = {ncorrect2/N:.3f}')"
      ],
      "metadata": {
        "id": "Fuj0EBeMaWQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "識別率が逆転しました．方法1では $p(\\mathbf{x}|y)$ に任意の正規分布を当てはめることができますが，そのせいで過適合が起きてしまったようです．\n",
        "\n",
        "この授業で説明している範囲のあれこれでもう少し改良できますが，省略します（当てはめる正規分布に少し制約条件を付ける，次元削減を適用する，等）．"
      ],
      "metadata": {
        "id": "u9vCIamfbh3L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "---\n",
        "## 正規分布モデルではうまくいかない例\n",
        "---\n",
        "\n",
        "「密度推定」や「統計的パターン認識入門」の notebook に出てくる2次元データの例は，正規分布の当てはめでうまくいく例ばかり見せていました．\n",
        "うまくいかない例を観察するのも大事ですから，ここでそういう例を紹介しておきます．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずはデータの準備．"
      ],
      "metadata": {
        "id": "4SLTdA9g4Evg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "moonX, moonY = make_moons(n_samples=(800, 200), noise=0.25)\n",
        "NL, NT = 500, 500\n",
        "XL, YL = moonX[:NL, :], moonY[:NL]\n",
        "XT, YT = moonX[NL:, :], moonY[NL:]\n",
        "print(XL.shape, YL.shape)\n",
        "print(XT.shape, YT.shape)"
      ],
      "metadata": {
        "id": "4vwBPRfKg2l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(9, 6))\n",
        "ax0 = fig.add_subplot(121)\n",
        "ax0.scatter(XL[YL==0, 0], XL[YL==0, 1], marker='.', label='Class0')\n",
        "ax0.scatter(XL[YL==1, 0], XL[YL==1, 1], marker='.', label='Class1')\n",
        "ax0.set_xlim(-1.5, 2.5)\n",
        "ax0.set_ylim(-2, 2)\n",
        "ax0.set_aspect('equal')\n",
        "ax0.legend()\n",
        "ax0.set_title('training data')\n",
        "\n",
        "\n",
        "ax1 = fig.add_subplot(122)\n",
        "ax1.scatter(XT[YT==0, 0], XT[YT==0, 1], marker='.', label='Class0')\n",
        "ax1.scatter(XT[YT==1, 0], XT[YT==1, 1], marker='.', label='Class1')\n",
        "ax1.set_xlim(-1.5, 2.5)\n",
        "ax1.set_ylim(-2, 2)\n",
        "ax1.set_aspect('equal')\n",
        "ax1.legend()\n",
        "ax1.set_title('test data')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "alG4tvn5h-In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2クラス識別の例です．左が学習データ，右がテストデータ．"
      ],
      "metadata": {
        "id": "oFELNNt-gX4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルでは，学習データから事前確率 $p(y)$ とクラスごとの分布 $p(\\mathbf{x}|y)$ を推定し，データをその事後確率 $p(y|\\mathbf{x})$ （に比例する $p(\\mathbf{x}|y)p(y)$ の値）が最大となるクラスに識別する実験が行なえます．"
      ],
      "metadata": {
        "id": "lUHMUsfGgjXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2\n",
        "N, D = XL.shape\n",
        "\n",
        "# 事前確率を推定\n",
        "P = np.empty(K)\n",
        "for k in range(K):\n",
        "    P[k] = np.sum(YL==k)/N\n",
        "print('P =', P)\n",
        "\n",
        "# クラスごとのデータの分布を多変量正規分布でモデル化\n",
        "mu = np.empty((K, D))\n",
        "cov = np.empty((K, D, D))\n",
        "model = np.empty(K, dtype=object)\n",
        "for k in range(K):\n",
        "    XX = XL[YL==k, :]\n",
        "    model[k] = GaussianMixture(n_components=1, covariance_type='full')\n",
        "    model[k].fit(XX)\n",
        "    mu[k, ::] = model[k].means_\n",
        "    cov[k, ::] = model[k].covariances_\n",
        "\n",
        "# 学習データの識別\n",
        "N = XL.shape[0]\n",
        "LL = np.empty((N, K))\n",
        "for n in range(N):\n",
        "    for k in range(K):\n",
        "        # log(p(y)p(x|y)) = log(p(y)) + log(p(x|y))\n",
        "        LL[n, k] = np.log(P[k]) + model[k].score_samples(XL[n, np.newaxis, :])\n",
        "Yp = np.argmax(LL, axis=1)\n",
        "ncorrect = np.sum(YL == Yp)\n",
        "print(f'学習データの識別率: {ncorrect/N}')\n",
        "\n",
        "# テストデータの識別\n",
        "N = XT.shape[0]\n",
        "LL = np.empty((N, K))\n",
        "for n in range(N):\n",
        "    for k in range(K):\n",
        "        # log(p(y)p(x|y)) = log(p(y)) + log(p(x|y))\n",
        "        LL[n, k] = np.log(P[k]) + model[k].score_samples(XT[n, np.newaxis, :])\n",
        "Yp = np.argmax(LL, axis=1)\n",
        "ncorrect = np.sum(YT == Yp)\n",
        "print(f'テストデータの識別率: {ncorrect/N}')"
      ],
      "metadata": {
        "id": "O0NlwPWZfT90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "識別率の数値だけではうまくいってるのかどうかわかりませんので，可視化してみましょう．"
      ],
      "metadata": {
        "id": "8BEVieqMh5EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "xmin, xmax = -1.5, 2.5\n",
        "ymin, ymax = -2, 2\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "print(X_mesh.shape)\n",
        "\n",
        "# 事後確率の推定\n",
        "p = np.empty((K, X_mesh.shape[0]*X_mesh.shape[1]))\n",
        "for k in range(K):\n",
        "    proba = np.exp(model[k].score_samples(X_mesh.reshape((-1, 2))))\n",
        "    p[k, :] = P[k] * proba\n",
        "p /= np.sum(p, axis=0)\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(12, 8))\n",
        "\n",
        "# 左図\n",
        "ax0 = fig.add_subplot(121)\n",
        "for k in range(K):\n",
        "    ax0.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    z = multivariate_normal.pdf(X_mesh, mean=mu[k], cov=cov[k])\n",
        "    ax0.contour(x_mesh, y_mesh, z, levels=4)\n",
        "ax0.set_xlim(xmin, xmax)\n",
        "ax0.set_ylim(ymin, ymax)\n",
        "ax0.set_aspect('equal')\n",
        "\n",
        "# 右図\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(122)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BJD7SiGafrVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "左図は2クラスの学習データと，それに当てはめられた正規分布を可視化したものです．2クラスそれぞれの $p(\\mathbf{x}|y)$ に単一の正規分布を当てはめるのでは，このデータのもつ複雑な分布を表しきれていないことは明らかですね．\n",
        "右図は，事後確率の値を可視化したものです．2クラスをうまく分けられていないことがわかります（※）．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 「多変量解析及び演習」の「判別分析」の回に，正規分布を当てはめる場合には識別境界が2次曲線になることを説明していました．\n",
        "</span>"
      ],
      "metadata": {
        "id": "dTv3GlhCiETC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 混合正規分布モデルを使ってみる\n",
        "---\n",
        "\n",
        "※ ここで紹介する「混合正規分布」については，授業の範囲ではありません．式の説明は，眺めるだけでok．"
      ],
      "metadata": {
        "id": "3GcR7kPPcFWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記で見たように，正規分布は単純すぎてうまくデータの分布を表現できないことがあります．\n",
        "そういう場合への対応の方法はいろいろありますが，ここでは，「複数の正規分布の重み付き和」で表される「混合正規分布モデル」(Gaussian mixture model)を紹介します．\n",
        "\n",
        "これは，$M$個の正規分布の重み付き和で，次のように表されます．\n",
        "$$\n",
        "p(\\mathbf{x}) = \\sum_{m=1}^{M} w_m{\\cal N}(\\mathbf{x}|\\mathbf{\\mu}_m, \\Sigma_m)\n",
        "$$\n",
        "${\\cal N}(\\mathbf{x}|\\mathbf{\\mu}_m, \\Sigma_m)$ は平均$\\mathbf{\\mu}_m$ 分散共分散行列 $\\Sigma_m$ の多変量正規分布です．$w_m$ は $m$ 番目の正規分布の重みを表し，$0 \\leq w_m \\leq 1, \\sum_{m=1}^M w_m = 1$ を満たします．\n",
        "混合正規分布モデルでは，$w_m, \\mathbf{\\mu}_m, \\Sigma_m$ がモデルパラメータとなります．"
      ],
      "metadata": {
        "id": "drlhv8wBcboy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2次元の「うまくいかない例」のデータに $M=3$ の混合正規分布モデルを当てはめてみると，こんなふうになります．"
      ],
      "metadata": {
        "id": "SfIEqZPOez8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2\n",
        "N, D = XL.shape\n",
        "M = 3\n",
        "\n",
        "# 事前確率を推定\n",
        "py = np.empty(K)\n",
        "for k in range(K):\n",
        "    py[k] = np.sum(YL==k)/N\n",
        "print('### 事前確率')\n",
        "print('p(y) = ', py)\n",
        "\n",
        "# p(x|y) をGMMでモデル化\n",
        "mu = np.empty((K, M, D))\n",
        "cov = np.empty((K, M, D, D))\n",
        "model = np.empty(K, dtype=object)\n",
        "for k in range(K):\n",
        "    XX = XL[YL==k, :]\n",
        "    model[k] = GaussianMixture(n_components=M, covariance_type='full')\n",
        "    model[k].fit(XX)\n",
        "    mu[k, ::] = model[k].means_\n",
        "    cov[k, ::] = model[k].covariances_\n",
        "\n",
        "# 学習データの識別\n",
        "N = XL.shape[0]\n",
        "LL = np.empty((N, K))\n",
        "for n in range(N):\n",
        "    for k in range(K):\n",
        "        # log(p(y)p(x|y)) = log(p(y)) + log(p(x|y))\n",
        "        LL[n, k] = np.log(P[k]) + model[k].score_samples(XL[n, np.newaxis, :])\n",
        "Yp = np.argmax(LL, axis=1)\n",
        "ncorrect = np.sum(YL == Yp)\n",
        "print(f'学習データの識別率: {ncorrect/N}')\n",
        "\n",
        "# テストデータの識別\n",
        "N = XT.shape[0]\n",
        "LL = np.empty((N, K))\n",
        "for n in range(N):\n",
        "    for k in range(K):\n",
        "        # log(p(y)p(x|y)) = log(p(y)) + log(p(x|y))\n",
        "        LL[n, k] = np.log(P[k]) + model[k].score_samples(XT[n, np.newaxis, :])\n",
        "Yp = np.argmax(LL, axis=1)\n",
        "ncorrect = np.sum(YT == Yp)\n",
        "print(f'テストデータの識別率: {ncorrect/N}')"
      ],
      "metadata": {
        "id": "80S58YAVcG7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習データテストデータともに，単一の正規分布を当てはめたときよりもずっと高い識別率が得られています．"
      ],
      "metadata": {
        "id": "nb46AcYXlGVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "クラスごとの分布と事後確率の推定値を可視化してみると，こんなん．"
      ],
      "metadata": {
        "id": "74cw0JHGlRIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "xmin, xmax = -1.5, 2.5\n",
        "ymin, ymax = -2, 2\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "print(X_mesh.shape)\n",
        "\n",
        "# 事後確率の推定\n",
        "p = np.empty((K, X_mesh.shape[0]*X_mesh.shape[1]))\n",
        "for k in range(K):\n",
        "    proba = np.exp(model[k].score_samples(X_mesh.reshape((-1, 2))))\n",
        "    p[k, :] = py[k] * proba\n",
        "p /= np.sum(p, axis=0)\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(12, 8))\n",
        "\n",
        "# Gaussian を当てはめた結果\n",
        "ax0 = fig.add_subplot(121)\n",
        "for k in range(K):\n",
        "    ax0.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    for m in range(M):\n",
        "        z = multivariate_normal.pdf(X_mesh, mean=mu[k, m], cov=cov[k, m])\n",
        "        ax0.contour(x_mesh, y_mesh, z, levels=4)\n",
        "ax0.set_xlim(xmin, xmax)\n",
        "ax0.set_ylim(ymin, ymax)\n",
        "ax0.set_aspect('equal')\n",
        "\n",
        "# 事後確率の可視化\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(122)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kMGSslK8kfJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`M = 3` のところの数を変えると，正規分布の数を変えられます．いろいろ変えてみるとよいでしょう（あまり多くするとエラーになるかもしれません）．\n",
        "\n",
        "手書き数字の例に混合正規分布モデルを使ってみるのも面白いのですが，省略します．"
      ],
      "metadata": {
        "id": "zYSrQn4CgDss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 識別モデルいろいろ\n",
        "---\n",
        "\n",
        "この notebook のここまでは，ex14notebookA「統計的パターン認識入門」で説明した方法，すなわち，事後確率 $p(y|\\mathbf{x})$ のかわりに事前確率 $p(y)$ とクラスごとのデータ分布 $p(\\mathbf{x}|y)$ を推定し $p(\\mathbf{x}|y)p(y)$ の値によって識別をするという方法の実験でした．このようにクラスごとのデータ分布 $p(\\mathbf{x}|y)$ の推定を経由して識別する方法は，生成モデルによる方法と呼ばれることがあります．\n",
        "\n",
        "一方，以前登場したロジスティック回帰やニューラルネットを用いる方法は，クラスごとのデータ分布の推定を経由せず，事後確率を直接モデル化する方法といえます．そのような方法は，生成モデルと対比させて，識別モデルによる方法と呼ばれることがあります．\n",
        "\n",
        "以下では，いくつかの代表的な識別モデルを用いて，上と同じデータの識別をさせてみましょう．"
      ],
      "metadata": {
        "id": "QnfPkM4b6iK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### ロジスティック回帰\n",
        "\n",
        "\n",
        "これまでも何度も話題に上がり，「機械学習・人工知能の歴史」でも触れたように，ロジスティック回帰は，線形分離可能なデータしかうまく識別できません．そのことを再確認しましょう．"
      ],
      "metadata": {
        "id": "QxcL5AXZ6wEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のコードセルを実行し，識別率や識別境界の形を確認しましょう．"
      ],
      "metadata": {
        "id": "7S6tJb4aA_O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの作成\n",
        "model = LogisticRegression(C=1.0, class_weight='balanced')\n",
        "\n",
        "# 学習\n",
        "model.fit(XL, YL)"
      ],
      "metadata": {
        "id": "IeDnhRbC7UfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 識別率の算出\n",
        "print('学習データの識別率:', model.score(XL, YL))\n",
        "print('テストデータの識別率:', model.score(XT, YT))"
      ],
      "metadata": {
        "id": "bvTnZHTv7uAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "xmin, xmax = -1.5, 2.5\n",
        "ymin, ymax = -2, 2\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "print(X_mesh.shape)\n",
        "\n",
        "# 事後確率の推定\n",
        "p = model.predict_proba(X_mesh.reshape((-1, 2))).T\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(6, 6))\n",
        "\n",
        "# 事後確率の可視化\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(111)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9_Wb459p72U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### Support Vector Machine 使ってみる\n",
        "\n",
        "\n",
        "「歴史」の話の中で登場した SVM (Support Vector Machine)です．"
      ],
      "metadata": {
        "id": "sltncWi2mN5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVMには様々なハイパーパラメータがあり，実際にはクロスバリデーション等の方法でそれらを決定するべきなのですが，ここでは決め打ちで実験することにします．興味のある人向けに補足しておくと，この実験では，RBF(Radial Basis Function)カーネルを用い，正則化パラメータ 'C' の値のみ何通りか変えられるようにしています．"
      ],
      "metadata": {
        "id": "4INd8GYq4Mx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの作成\n",
        "model = SVC(C=1.0, kernel='rbf', probability=True, class_weight='balanced')\n",
        "\n",
        "# 学習\n",
        "model.fit(XL, YL)"
      ],
      "metadata": {
        "id": "dCxlclEjhNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 識別率の算出\n",
        "print('学習データの識別率:', model.score(XL, YL))\n",
        "print('テストデータの識別率:', model.score(XT, YT))"
      ],
      "metadata": {
        "id": "t3r_xfIsyaxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "xmin, xmax = -1.5, 2.5\n",
        "ymin, ymax = -2, 2\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "print(X_mesh.shape)\n",
        "\n",
        "# 事後確率の推定\n",
        "p = model.predict_proba(X_mesh.reshape((-1, 2))).T\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(6, 6))\n",
        "\n",
        "# 事後確率の可視化\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(111)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tzJKYBcyyobQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一度動かしたら，次の `C` の値（正則化パラメータ）を 0.01 や 100.0 等に変えて実行してみるとよいでしょう．\n",
        "\n",
        "```\n",
        "# モデルの作成\n",
        "model = SVC(C=1.0, kernel='rbf', probability=True, class_weight='balanced')\n",
        "```"
      ],
      "metadata": {
        "id": "TgIGrAzaBvp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### ニューラルネット使ってみる\n",
        "\n",
        "階層型ニューラルネット（多層パーセプトロン）使ってみましょう．"
      ],
      "metadata": {
        "id": "1eJQdN7O8Nho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "階層型ニューラルネットの場合，ネットワークに中間層をいくつ持たせるか，それぞれの中間層のニューロン数をいくつにするか，活性化関数にどんなものを用いるか，等々のハイパーパラメータがありますが，ここでは一通りに決め打ちで実験します．"
      ],
      "metadata": {
        "id": "7Gd13lbkCLrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの作成\n",
        "model = MLPClassifier(hidden_layer_sizes=[1000, 1000], activation='relu', verbose=True)\n",
        "\n",
        "# 学習\n",
        "model.fit(XL, YL)"
      ],
      "metadata": {
        "id": "adWoT-jizIC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 識別率の算出\n",
        "print('学習データの識別率:', model.score(XL, YL))\n",
        "print('テストデータの識別率:', model.score(XT, YT))"
      ],
      "metadata": {
        "id": "qmpPVioZ8vei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "xmin, xmax = -1.5, 2.5\n",
        "ymin, ymax = -2, 2\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "print(X_mesh.shape)\n",
        "\n",
        "# 事後確率の推定\n",
        "p = model.predict_proba(X_mesh.reshape((-1, 2))).T\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(6, 6))\n",
        "\n",
        "# 事後確率の可視化\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(111)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[YL==k, 0], XL[YL==k, 1])\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KRhWqCPQ9TDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tlBtA5gV9d-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
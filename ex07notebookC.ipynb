{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2023/ex07notebookC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex07notebookC\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2023)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## 事前学習済みニューラルネットを動かしてみよう\n",
        "----\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glgWbdlh34P"
      },
      "source": [
        "----\n",
        "### 準備\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPUを利用するようにランタイムのタイプを変更する\n"
      ],
      "metadata": {
        "id": "3xaSo__5tMel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "この notebook の後半の画像生成のコードは，GPU を利用できる環境でないと動きません．次のようにしてランタイムのタイプを変更してから実行してください．\n",
        "\n",
        "1. メニューの「ランタイム」 > 「ランタイムのタイプを変更」 を選択．\n",
        "1. 「ノートブックの設定」というポップアップウィンドウが開くので，「ハードウェアアクセラレータ」を「None」から「GPU」に変更し，「保存」する\n",
        "1. いつもどおりコードセルを実行する．すでに実行していた場合，「以前のランタイムを削除する」というポップアップウィンドウが現れるので，「OK」を押しし，一番最初のコードセルから実行し直ます．\n"
      ],
      "metadata": {
        "id": "DHWsvGROH9y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### いろいろ import"
      ],
      "metadata": {
        "id": "b52pSlrFynUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "import io\n",
        "import requests\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 関係のほげ\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision.io.image import read_image\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "hqKwr1oJD4mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU が使えるようになっていれば，↑のセルを実行すると `cuda:0` と出力されるはずです．\n"
      ],
      "metadata": {
        "id": "lmSbyUjm1MSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 実験1 物体検出\n",
        "\n",
        "notebookB では，「一枚の画像全体に何が写っているかを認識する」識別問題を扱うニューラルネットを動かしましたが，ここでは，「一枚の画像の中に写っている複数の物体を検出する」問題を扱うニューラルネットを動かしてみましょう．このニューラルネットは，一枚の画像を入力すると，画像中の物体ごとに，その位置とそれが何であるかを表す情報を出力します．\n",
        "\n",
        "ここでは，FasterRCNN と呼ばれる，畳み込みニューラルネットによる物体検出の仕組みの事前学習済みモデルを使います．\n",
        "このモデルは，COCO (https://cocodataset.org/) と呼ばれる大規模画像データセットで 81 種類の物体の検出を学習したものです．\n",
        "\n",
        "\n",
        "- Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,\" NeurIPS 2015, https://arxiv.org/abs/1506.01497\n",
        "- https://pytorch.org/vision/0.15/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html\n"
      ],
      "metadata": {
        "id": "szdqM433mzUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FasterRCNN の事前学習済みモデルを入手\n",
        "\n",
        "weights = models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
        "preprocess = weights.transforms()\n",
        "model = models.detection.fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.9)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "#print(model)\n",
        "\n",
        "# 物体のクラスの一覧を出力\n",
        "n = 0\n",
        "for cn in weights.meta[\"categories\"]:\n",
        "    if cn != 'N/A':\n",
        "        print(n, cn, end='\\n')\n",
        "        n += 1"
      ],
      "metadata": {
        "id": "MGHUhrwpy1I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実験用のサンプル画像を入手します．これらは，COCOデータセットの学習用または評価用のデータの一部です．"
      ],
      "metadata": {
        "id": "leVkuWnycQ67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像を入手\n",
        "\n",
        "urlDict = {\n",
        "    'dog':'https://farm6.staticflickr.com/5124/5379029845_60f6314172_z.jpg',\n",
        "    'cats':'https://farm1.staticflickr.com/16/23200321_dcff6ba227_z.jpg',\n",
        "    'carelephant':'https://farm8.staticflickr.com/7157/6822207699_71e174fd3f_z.jpg',\n",
        "    'bicycles':'https://farm1.staticflickr.com/33/67728109_0d11a646ef_z.jpg',\n",
        "    'teddybears':'https://farm4.staticflickr.com/3584/3554604954_2e01e4d007_z.jpg',\n",
        "}\n",
        "\n",
        "for key in urlDict.keys():\n",
        "    rv = requests.get(urlDict[key])\n",
        "    assert rv.status_code == 200, '画像のダウンロードに失敗しました'\n",
        "    with io.BytesIO(rv.content) as buf:\n",
        "        img = Image.open(buf)\n",
        "        fn = f'{key}.png'\n",
        "        print(fn)\n",
        "        img.save(fn)"
      ],
      "metadata": {
        "id": "GB2BmM_PD1WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 物体検出\n",
        "#@markdown 以下で 0 から 4 までの数をひとつ選んでからこのセルを実行すると，物体検出の結果が表示されます．\n",
        "i = 0 #@param [0, 1, 2, 3, 4] {type: 'raw'}\n",
        "\n",
        "key = list(urlDict.keys())[i]\n",
        "fn = f'{key}.png'\n",
        "print(fn)\n",
        "\n",
        "# 画像を読み込んでモデルへの入力に加工\n",
        "img = read_image(fn)\n",
        "X = torch.unsqueeze(preprocess(img), axis=0).to(device)\n",
        "\n",
        "# モデルの出力を計算\n",
        "Y = model(X)[0]\n",
        "\n",
        "# 出力の情報を画像に加工\n",
        "labels = [weights.meta['categories'][i] for i in Y['labels']]\n",
        "bbox = draw_bounding_boxes(img, boxes=Y['boxes'], labels=labels, colors='#00ff00', width=3)\n",
        "imgResult = to_pil_image(bbox.detach())\n",
        "imgResult.show()\n"
      ],
      "metadata": {
        "id": "agQUgL5CW2in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，適当な画像ファイルを Colab 上へアップロードできます．いろいろ試してみましょう．"
      ],
      "metadata": {
        "id": "BzkKHboCdLWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab へファイルをアップロード\n",
        "from google.colab import files\n",
        "rv = files.upload()\n",
        "\n",
        "# ファイル一覧\n",
        "! ls"
      ],
      "metadata": {
        "id": "c1J_Vmn8iUmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルの1行目のファイル名をアップロードしたものに変更してから実行すると，物体検出してくれます．"
      ],
      "metadata": {
        "id": "svvAJgZidWLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn = 'teddybears.png' # ここを拡張子含めてアップロードしたファイルの名前に変更\n",
        "\n",
        "print(fn)\n",
        "img = read_image(fn)\n",
        "X = torch.unsqueeze(preprocess(img), axis=0).to(device)\n",
        "Y = model(X)[0]\n",
        "labels = [weights.meta['categories'][i] for i in Y['labels']]\n",
        "bbox = draw_bounding_boxes(img, boxes=Y['boxes'], labels=labels, colors='#00ff00', width=3)\n",
        "imgResult = to_pil_image(bbox.detach())\n",
        "imgResult.show()"
      ],
      "metadata": {
        "id": "EExunq0fXKrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験2 画像生成\n",
        "\n",
        "次は，Stable Diffusion と呼ばれる画像生成モデルを動かしてみます． Stable Diffusion は，\n",
        "[Stability AI](https://ja.stability.ai/)が開発・提供しているものです．\n",
        "ウェブ上で試用できます（ https://stablediffusionweb.com/ )が，学習済みモデルが公開されていますので，それを入手して自分のPCで動かしてみることもできます．ここでは， Colab 上で動かしてみましょう．\n",
        "\n",
        "- Stable Diffusion の中心にある Latent Diffusion Model に関する論文: \n",
        "R. Rombach, A. Blattmann, D. Lorenz, P. Esser, B Ommer, ''[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)'', CVPR2022\n",
        "- Wikipedia の記事: https://ja.wikipedia.org/wiki/Stable_Diffusion"
      ],
      "metadata": {
        "id": "Z3UL98t0dsoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "準備として，標準の Colab の環境にはインストールされていないソフトウェアパッケージをいくつか追加でインストールします．"
      ],
      "metadata": {
        "id": "CbrO22uWfRTD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxqhTw8tDgBS"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前学習済みモデルをダウンロードします．巨大なモデルでパラメータ数が膨大なので，少し時間がかかります．"
      ],
      "metadata": {
        "id": "ulHWfBV5gL6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "model_id = 'stabilityai/stable-diffusion-2'\n",
        "\n",
        "# ノイズスケジューラの設定\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder='scheduler')\n",
        "# モデルとそのパラメータの入手\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision='fp16', torch_dtype=torch.float16)\n",
        "# GPU を使う設定にする\n",
        "assert torch.cuda.is_available(), 'この実験はGPUが使える環境でないとできません'\n",
        "pipe = pipe.to('cuda')"
      ],
      "metadata": {
        "id": "9tWekRZRfJ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下の `prompt` に記したテキスト（プロンプト）をもとに画像を生成します．ランダム性があるので，同じプロンプトでも実行の度に生成結果は変わります．何度か実行してみるとよいでしょう．"
      ],
      "metadata": {
        "id": "PQf2HgT7gWpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'a photo of an astronaut riding a horse on mars'\n",
        "image = pipe(prompt).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "xRIziv-GgBSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "引数でいろいろ指定できます．詳しいことが知りたいひとは，リンク先のドキュメントを参照してください．\n",
        "\n",
        "https://huggingface.co/docs/diffusers/v0.16.0/en/api/pipelines/stable_diffusion/text2img\n",
        "\n"
      ],
      "metadata": {
        "id": "W9kJZLKClael"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'a photo of a man facing his laptop computer and a cat sleeping on the laptop computer'\n",
        "neg_prompt = 'black cat'\n",
        "image = pipe(prompt, negative_prompt=neg_prompt, guidance_scale=7.5).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "E50Xkpglgodh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'a figure of mount Fuji erupting with flash of lightning, plume and lava'\n",
        "neg_prompt = None\n",
        "image = pipe(prompt, negative_prompt=neg_prompt, guidance_scale=15.0).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "W4FYjmihhXAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "自分で適当なプロンプトを指定していろいろ試してみてね．"
      ],
      "metadata": {
        "id": "Lo6W-BRG2EDo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yI-IcxQUnFpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2024/ML2024_ex10notebookC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex10notebookC\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## 過適合の抑制とモデル選択 (3)\n",
        "----\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ゴリゴリ君\n",
        "\n",
        "「ゴリゴリ君」のデータで，検証データを用いてモデルやハイパーパラメータの値を選択する実験をやってみよう．\n"
      ],
      "metadata": {
        "id": "Ede1PLHlMiRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずはいつものように準備から．\n",
        "\n"
      ],
      "metadata": {
        "id": "m_05KKmfwFQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# scikit-learn のいろいろ\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# データを読み込む\n",
        "dfGori = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/gorigori.csv', header=0)"
      ],
      "metadata": {
        "id": "Uba-rqwa906l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これまでは，気温やアイス売上数の値をそのまま使っていましたが，今回は正規化して実験します．ただし，適当な数で割るだけという簡易的な方法です．"
      ],
      "metadata": {
        "id": "CuioRtpH_bb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを正規化\n",
        "dfGori['気温'] /= 40\n",
        "dfGori['アイス売上数'] /= 150"
      ],
      "metadata": {
        "id": "fpR8qBDi-yKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルは，実験用の関数の定義です．"
      ],
      "metadata": {
        "id": "QjOrPD-R_vgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1, x, x^2, x^3, ..., X^D をならべたデータ行列（N x (D+1)）をつくる\n",
        "#\n",
        "def makeDataMatrix(x, D):\n",
        "\n",
        "    N = x.shape[0]\n",
        "    X = np.zeros((N, D+1))\n",
        "    X[:, 0] = 1\n",
        "    for i in range(1, D+1):\n",
        "        X[:, i] = x**i\n",
        "\n",
        "    return X\n",
        "\n",
        "##  正規方程式を解く（正則化付き）\n",
        "#\n",
        "def solve(X, y, alpha=0.0):\n",
        "\n",
        "    N = X.shape[0]\n",
        "    A = np.dot(X.T, X)\n",
        "    b = np.dot(X.T, y)\n",
        "    if alpha > 0.0:\n",
        "        Dp1 = X.shape[1]\n",
        "        Id = np.eye(Dp1)\n",
        "        Id[0, 0] = 0.0\n",
        "        A += alpha * Id\n",
        "\n",
        "    # x is the solution of the equation Ax = b\n",
        "    x = np.linalg.solve(A, b)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "LiQE4UJS99xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下で実験を行います．ここでは，次のような条件で多項式当てはめのモデルを学習させます．\n",
        "\n",
        "- 多項式の次数: $D = 10$ と $D = 20$ の2通り\n",
        "- 正則化項の係数: $\\alpha = 0, 0.001, 0.01, 0.1$ の4通り\n",
        "\n",
        "それぞれを組み合わせた8通りの条件で学習を行い，汎化性能が最も高いと予想される条件を探します．\n",
        "それぞれの条件で$n$-分割交差検証を行い，$n$通り得られる検証誤差の平均値を汎化性能の指標とします．$n$ は以下のコード中の変数 `nfold` で指定しています．\n",
        "$n$-分割交差検証のためにデータを分割する処理には，[sklearn.model_selection.KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) を利用することにします．"
      ],
      "metadata": {
        "id": "YrM2iA3F_02T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットをいくつの組に分割するか\n",
        "nfold = 5\n",
        "\n",
        "# n-分割交差検証のための KFold クラスのインスタンスを生成\n",
        "kf = KFold(n_splits=nfold, shuffle=True, random_state=2929)\n",
        "\n",
        "msqeL = {}\n",
        "msqeV = {}\n",
        "\n",
        "# 多項式の次数 D\n",
        "for D in [10, 20]:\n",
        "\n",
        "    # 学習用と検証用のデータを準備\n",
        "    Xorg = makeDataMatrix(dfGori['気温'].to_numpy(), D)\n",
        "    Yorg = dfGori['アイス売上数'].to_numpy()\n",
        "\n",
        "    # 正則化項の係数 alpha\n",
        "    for alpha in [0.0, 0.001, 0.01, 0.1]:\n",
        "\n",
        "        msqeLsub = np.empty(nfold)\n",
        "        msqeVsub = np.empty(nfold)\n",
        "\n",
        "        # nfold 組のデータのうち一つで学習と検証\n",
        "        for i, (idxL, idxV) in enumerate(kf.split(Xorg)):\n",
        "            # データを学習用と検証用に分ける\n",
        "            XL, YL = Xorg[idxL], Yorg[idxL]\n",
        "            XV, YV = Xorg[idxV], Yorg[idxV]\n",
        "            # 正則化付き最小二乗法でD次多項式を当てはめ\n",
        "            w = solve(XL, YL, alpha=alpha)\n",
        "            # 学習データと検証データに対する平均二乗誤差を計算\n",
        "            msqeLsub[i] = np.mean(np.square(YL - XL@w))\n",
        "            msqeVsub[i] = np.mean(np.square(YV - XV@w))\n",
        "\n",
        "        # nfold 回の学習で得られた平均二乗誤差の平均を記録\n",
        "        msqeL[(D, alpha)] = np.mean(msqeLsub)\n",
        "        msqeV[(D, alpha)] = np.mean(msqeVsub)\n"
      ],
      "metadata": {
        "id": "3l4rJeSY-FLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記では，8通りの条件のそれぞれについて，5通りの学習-検証データの組を使って学習と検証を行っています．\n",
        "以下のセルを実行すると，それぞれの条件について，5-分割交差検証によって得られた，学習データに対する平均二乗誤差の平均（`msqeL`）と，検証データに対する平均二乗誤差の平均（`msqeV`）が表示されます．"
      ],
      "metadata": {
        "id": "dJ8Xca1yA-Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key in msqeL.keys():\n",
        "    D, alpha = key\n",
        "    print(f'D = {D} alpha = {alpha}   msqeL = {msqeL[key]:.3e}   msqeV = {msqeV[key]:.3e}')"
      ],
      "metadata": {
        "id": "iL2kMtte-M7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の結果を見て，これら8通りの条件のうち，汎化性能が最も高そうなものを選んで，その条件を紙にメモしておきましょう．\n",
        "\n",
        "また，その条件を以下のセルの `D = ???` と `alpha = ???` のところに指定してセルを実行してみましょう．\n",
        "このセルでは，指定した条件で，全ての学習データを用いて再度学習を行い，その結果を表示します．"
      ],
      "metadata": {
        "id": "-xaas7UMBpYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# すべてのデータを使って多項式当てはめ\n",
        "D = 20\n",
        "alpha = 0.0\n",
        "Xorg = makeDataMatrix(dfGori['気温'].to_numpy(), D)\n",
        "Yorg = dfGori['アイス売上数'].to_numpy()\n",
        "w = solve(Xorg, Yorg, alpha=alpha)\n",
        "\n",
        "# 曲線の式の値を計算\n",
        "Xr =  np.linspace(0, 1, 100)\n",
        "XXr = makeDataMatrix(Xr, D)\n",
        "Yest = XXr @ w\n",
        "print(Yest.shape)\n",
        "\n",
        "# グラフを描く\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(8, 6))\n",
        "ax.scatter(Xorg[:, 1], Yorg)\n",
        "ax.plot(Xr, Yest, color='red', label=f'D = {D}, $\\\\alpha$ = {alpha}')\n",
        "ax.set_xlim(0.0, 1)\n",
        "ax.set_ylim(0.0, 1)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HeXvo4Rz-rhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 手書き数字画像の識別\n",
        "\n",
        "何度も使っている手書き数字画像の問題に階層型ニューラルネットワークを適用して，モデルを選択してみましょう．"
      ],
      "metadata": {
        "id": "LKUdGZzpRRsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 手書き数字データの入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/minimnist.npz\n",
        "minimnist = np.load('minimnist.npz')\n",
        "XLorg = minimnist['datL'].astype(float)\n",
        "YLorg = minimnist['labL']\n",
        "XT = minimnist['datT']\n",
        "YT = minimnist['labT']\n",
        "\n",
        "K = 10 # クラス数\n",
        "D = XLorg.shape[1] # データの次元数 28 x 28 = 784"
      ],
      "metadata": {
        "id": "aW9hRlfj_TaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下で実験を行います．ここでは，次の6通りのニューラルネットの中から，汎化性能が最も高いと予想されるものを選ぶことにします．\n",
        "\n",
        "- ニューロン数 100-10 の2層ニューラルネット（中間層のニューロン数が1000で出力層のニューロン数が10）\n",
        "- ニューロン数 500-10 の2層ニューラルネット\n",
        "- ニューロン数 1000-10 の2層ニューラルネット\n",
        "- ニューロン数 100-100-10 の3層ニューラルネット\n",
        "- ニューロン数 500-100-10 の3層ニューラルネット（入力に近い方の中間層のニューロン数が500，出力に近い方の中間層のニューロン数が100）\n",
        "- ニューロン数 1000-100-10 の3層ニューラルネット\n",
        "\n",
        "それぞれのニューラルネットの学習の際には$n$-分割交差検証を行い，$n$通り得られる検証データの正答率の平均値を汎化性能の指標とします．$n$ は以下のコード中の変数 `nfold` で指定しています．"
      ],
      "metadata": {
        "id": "DnH_hEQFbMc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットをいくつの組に分割するか\n",
        "nfold = 3\n",
        "\n",
        "# n-分割交差検証のための KFold クラスのインスタンスを生成\n",
        "kf = KFold(n_splits=nfold, shuffle=True, random_state=2929)\n",
        "\n",
        "scoreL = {}\n",
        "scoreV = {}\n",
        "\n",
        "# ニューロン数\n",
        "HL_list = [(100, ), (500, ), (1000,), (100, 100), (500, 100), (1000, 100)]\n",
        "\n",
        "for HL in HL_list:\n",
        "\n",
        "    print('ニューロン数', end=' ')\n",
        "    if len(HL) == 1:\n",
        "        print(f'{HL[0]}-{K}')\n",
        "    elif len(HL) == 2:\n",
        "        print(f'{HL[0]}-{HL[1]}-{K}')\n",
        "\n",
        "    scoreLsub = np.empty(nfold)\n",
        "    scoreVsub = np.empty(nfold)\n",
        "\n",
        "    # nfold 組のデータのうち一つで学習と検証\n",
        "    for i, (idxL, idxV) in enumerate(kf.split(XLorg)):\n",
        "\n",
        "        print(f'{i+1}/{nfold}')\n",
        "\n",
        "        # データを学習用と検証用に分ける\n",
        "        XL, YL = XLorg[idxL], YLorg[idxL]\n",
        "        XV, YV = XLorg[idxV], YLorg[idxV]\n",
        "        # ニューラルネットの学習\n",
        "        model = MLPClassifier(hidden_layer_sizes=HL)\n",
        "        model.fit(XL, YL)\n",
        "        # 学習データと検証データに対する識別率を算出\n",
        "        scoreLsub[i] = model.score(XL, YL)\n",
        "        scoreVsub[i] = model.score(XV, YV)\n",
        "\n",
        "    # nfold 回の学習で得られた平均二乗誤差の平均を記録\n",
        "    scoreL[HL] = np.mean(scoreLsub)\n",
        "    scoreV[HL] = np.mean(scoreVsub)"
      ],
      "metadata": {
        "id": "4ewWDfuoSm8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，それぞれのニューラルネットについて，3通りの学習データに対する正答率の平均（`scoreL`）と，3通りの検証データに対する正答率の平均（`scoreV`）が表示されます．"
      ],
      "metadata": {
        "id": "4I4-9OO4dZ7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for HL in scoreL.keys():\n",
        "    print('ニューロン数', end=' ')\n",
        "    if len(HL) == 1:\n",
        "        print(f'{HL[0]}-{K}', end=' ')\n",
        "    elif len(HL) == 2:\n",
        "        print(f'{HL[0]}-{HL[1]}-{K}', end=' ')\n",
        "    print(f'  scoreL = {scoreL[HL]:.3f}   scoreV = {scoreV[HL]:.3f}')"
      ],
      "metadata": {
        "id": "-tRyI4u_UJeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の結果を見て，これらの中で最も汎化性能が最も高そうなモデルを選んで，その構造（層の数やニューロン数）を紙にメモしておきましょう．\n",
        "\n",
        "また，次のセルの `hidden_layer_sizes=(10,)` のところを適切に修正して実行すると，全ての学習データを使ってもう一度学習を行い，テストデータに対する正答率を算出します．選んだニューラルネットでやってみましょう．"
      ],
      "metadata": {
        "id": "s0vKpu-zd91T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPClassifier(hidden_layer_sizes=(10,))\n",
        "model.fit(XLorg, YLorg)\n",
        "scoreT = model.score(XT, YT)\n",
        "print(f'scoreT = {scoreT:.3f}')"
      ],
      "metadata": {
        "id": "hHQ2L8miVKsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "95mqpdn0Yi4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
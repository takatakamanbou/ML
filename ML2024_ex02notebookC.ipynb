{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2024/ML2024_ex02notebookC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex02notebookC\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfD2FEfXh34O"
      },
      "source": [
        "----\n",
        "## カリフォルニアの住宅価格の予測\n",
        "----\n",
        "\n",
        "回帰のための教師あり学習の応用として，平面当てはめによってアメリカカリフォルニアの住宅価格を予測してみましょう．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "VjU5yWnF3wR4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# scikit-learn のいろいろ\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで使うのは，California housing dataset という，アメリカカリフォルニアの住宅価格を予測する回帰問題のデータセットです．\n",
        "\n",
        "参考\n",
        "- https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n",
        "- https://atmarkit.itmedia.co.jp/ait/articles/2201/31/news042.html"
      ],
      "metadata": {
        "id": "puRRq_XbBWes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データの入手"
      ],
      "metadata": {
        "id": "FOQtU2tLhJTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，データセットを入手できます．\n",
        "\n",
        "参考: scikit-learn の [sklearn.datasets.fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) 関数"
      ],
      "metadata": {
        "id": "nc_WPkZ_GGdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# as_frame を True にすると pandas.DataFrame 形式で取得できる\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "dfX = data['data']\n",
        "dfX"
      ],
      "metadata": {
        "id": "UUuJmhmY95lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "見て分かるように，8つの値から成るデータが20640件あります．これらは回帰モデルへの入力となります．\n",
        "1件のデータは，一定の地域内に存在する住宅および住人について求めた次の8つの値から成ります（詳細は↑の参考リンク先参照）．\n",
        "\n",
        "1. MedInc: 所得の中央値\n",
        "1. HouseAge: 築年数の中央値\n",
        "1. AveRooms: 部屋数の平均値\n",
        "1. AveBedrms: 寝室数の平均値\n",
        "1. Population: 人口\n",
        "1. AveOccup: 世帯数の平均値\n",
        "1. Latitude: 緯度\n",
        "1. Longitude: 経度\n",
        "\n",
        "予測対象はその地域の住宅価格の中央値で，次のような値です．"
      ],
      "metadata": {
        "id": "s3WEaZ8QGqC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfY = data['target']\n",
        "dfY"
      ],
      "metadata": {
        "id": "BFGZeuRQUPha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，このデータセットの中で住宅価格が最小と最大のデータを表示させることができます．"
      ],
      "metadata": {
        "id": "BMiYY2V6idmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y の値が最小と最大の行を表示\n",
        "imin, imax = dfY.argmin(), dfY.argmax()\n",
        "dfX.iloc[[imin, imax], :]"
      ],
      "metadata": {
        "id": "zFBgu-c5iuWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1行目が住宅価格最小の地域，2行目が最大の地域のデータです．"
      ],
      "metadata": {
        "id": "gakv5xB9iq2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 前処理"
      ],
      "metadata": {
        "id": "AFFBPjQIhl4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルを実行すると，データセットを，パラメータの学習に使うデータ（学習データ）と予測精度の検証に使うデータ（検証データ）に分割します．\n",
        "\n",
        "参考: [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m-E5ioBnHbP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 全データの 8 割を学習データとし，残りを検証データとする\n",
        "#   random_state を指定しなければ実行のたびに分割の仕方が変わるので毎回異なる実験結果となるが，\n",
        "#   ここでは一つの値に固定しているで，何度やっても（当然，誰がやっても）同じ条件で実験できる\n",
        "XL, XV, yL, yV = train_test_split(dfX.to_numpy(), dfY.to_numpy(), train_size=0.8, random_state=0)\n",
        "print(XL.shape, yL.shape, XV.shape, yV.shape)"
      ],
      "metadata": {
        "id": "MvfFn0Uy6pYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "入力となる8つの変数のばらつき方が変数ごとに違いすぎるので，各変数の平均が 0 で分散が 1 となるようにする前処理（標準化）を適用しておきます．\n",
        "\n",
        "参考: [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
      ],
      "metadata": {
        "id": "lVQ8MBAZh9hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XLの変数ごとの平均と分散を求める\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(XL)\n",
        "print(scaler.mean_) # 平均\n",
        "print(scaler.var_) # 分散\n",
        "\n",
        "# 求めた平均と分散を使って XL, XV を標準化\n",
        "XL2 = scaler.transform(XL)\n",
        "XV2 = scaler.transform(XV)"
      ],
      "metadata": {
        "id": "Ih0rbr9DiIl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 最小二乗法による平面当てはめ"
      ],
      "metadata": {
        "id": "BgYV8r5x45OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XL2 に 1 を付け足して Nx(D+1) 行列 X をつくる\n",
        "X = np.vstack((np.ones(len(XL2)), XL2.T)).T\n",
        "print(X.shape)\n",
        "print(X)"
      ],
      "metadata": {
        "id": "x0efHdi_Wzjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規方程式を解く\n",
        "XTX = X.T @ X  # 正規方程式の左辺の(D+1)x(D+1)の行列\n",
        "XTY = X.T @ yL  # 正規方程式の右辺の(D+1)x1の行列\n",
        "w = np.linalg.solve(XTX, XTY) # 連立方程式を解く\n",
        "print(f'{len(w)}個のパラメータの値は')\n",
        "print(w)"
      ],
      "metadata": {
        "id": "FUiaDT_CYzIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習データに対して二乗誤差の和を最小にするパラメータ $\\mathbf{w} = (w_0, w_1, \\ldots, w_{8})$ の値が得られました．\n",
        "\n",
        "MedInc （を標準化した値）に対する係数が 0.83 と大きいので，所得が高い地域ほど住宅価格も高くなる傾向にあるようです．一方，Latitude と Longitude の係数は負です．Latitude は北に行くほど大きくなりますので、南の方が住宅価格が高くなりがちなようです．"
      ],
      "metadata": {
        "id": "sXIh9lepZtnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 予測してみる\n",
        "\n",
        "\n",
        "得られたパラメータでどの程度うまく住宅価格を予測できるか，学習データと検証データのそれぞれで確認してみましょう．"
      ],
      "metadata": {
        "id": "5OYQA04Z5X-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データに対する予測値を求める\n",
        "XXL = np.vstack((np.ones(len(XL2)), XL2.T)).T\n",
        "YYL = XXL @ w\n",
        "print(XXL.shape, YYL.shape)\n",
        "\n",
        "# 最初の10件を表示\n",
        "for i in range(10):\n",
        "    print(f'{i}  入力', end=' ')\n",
        "    for x in XL2[i, :]:\n",
        "        print(f'{x: .3f}', end=' ')\n",
        "    print(f'  予測値 {YYL[i]:.3f}  正解 {yL[i]:.3f}  誤差の二乗 {(YYL[i] - yL[i])**2:.3f}')"
      ],
      "metadata": {
        "id": "etuZOWhvmY7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 検証データに対する予測値を求める\n",
        "XXV = np.vstack((np.ones(len(XV2)), XV2.T)).T\n",
        "YYV = XXV @ w\n",
        "print(XXV.shape, YYV.shape)\n",
        "\n",
        "# 最初の10件を表示\n",
        "for i in range(10):\n",
        "    print(f'{i}  入力', end=' ')\n",
        "    for x in XV2[i, :]:\n",
        "        print(f'{x: .3f}', end=' ')\n",
        "    print(f'  予測値 {YYV[i]:.3f}  正解 {yV[i]:.3f}  誤差の二乗 {(YYV[i] - yV[i])**2:.3f}')"
      ],
      "metadata": {
        "id": "-jDx1n0lkY7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "それなりに予測できているものもあれば，大きく外しているものもあるようです．\n",
        "\n",
        "どれくらいうまく予測できているか定量的に判断するために，学習データと検証データのそれぞれについて，予測値と正解の値との間の平均二乗誤差（残差平方和をデータ数で割った値）を求めると，次のようになります．"
      ],
      "metadata": {
        "id": "LHyQXcrAkVit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データ/検証データに対する出力と正解との間の平均二乗誤差\n",
        "msqeL = np.mean((YYL - yL)**2)\n",
        "msqeV = np.mean((YYV - yV)**2)\n",
        "print(f'(学習データの平均二乗誤差) = {msqeL:.4f}  (検証データの平均二乗誤差) =  {msqeV:.4f}')"
      ],
      "metadata": {
        "id": "1y5RePU0mAbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習に使わなかった検証データに対する平均二乗誤差の方が，少しだけ大きいようです．"
      ],
      "metadata": {
        "id": "jerWw312nWbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ★ やってみよう\n",
        "\n",
        "結果等はノート等（紙媒体）にメモしておこう\n",
        "\n",
        "1. ここで考えているモデルにはパラメータはいくつあるか\n",
        "1. 検証データの最初の10件のうち，誤差の二乗を基準として，予測が最もうまくいっているものと最もうまくいっていないものはどれか（値をメモしておこう）．\n"
      ],
      "metadata": {
        "id": "hL2Bexn7h4EK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 顔画像からの年齡推定\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### はじめに\n",
        "\n",
        "平面当てはめの応用例として，顔画像からそこに写った人物の年齡を推定するデモを作ってみました．\n",
        "画素値を並べたものに平面を当てはめる，という単純なモデルですので，推定精度は高くありません．\n",
        "推定精度を高めたければ，もっと複雑なモデルを使うことになります．\n",
        "\n",
        "人の顔が中央に大きく写った幅64画素高さ64画素の3チャンネルカラー画像 38,138 枚があります．\n",
        "これらの画像に写った人物の年齡を表す整数値も与えられています．\n",
        "このとき，一つの画像の画素値を1列にならべて $64\\times 64\\times 3 = 12288$ 次元ベクトルとみなせば，そこから年齡を予測する問題を重回帰分析の問題として定式化できます．\n",
        "\n",
        "ひとつの顔に対応する $12288$ 次元ベクトルに $1$ を付け足した $12289$ 次元ベクトルを $\\mathbf{x}$ とおき，そのひとの年齡を $y$ とおくとき，\n",
        "\n",
        "$$\n",
        "y \\approx \\mathbf{w}\\cdot\\mathbf{x}\n",
        "$$\n",
        "\n",
        "となるような $(D+1)$次元ベクトル $\\mathbf{w}$ を最小二乗法によって求める，というわけです（実際には，データの次元数が大きすぎるので，主成分分析を利用した次元削減も併用しています．詳しくはこの notebook の後の方に書いてます）．\n",
        "\n",
        "この notebook では，上記の設定で既に学習済みの $\\mathbf{w}$ を用いて，適当な画像 $\\mathbf{x}$ を与えて年齡推定をさせてみます．\n"
      ],
      "metadata": {
        "id": "udr_9OQzR2d_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "6qnegh5zVlHh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I226xIKJbqtM"
      },
      "source": [
        "# 必要なパッケージのインポート\n",
        "import numpy as np\n",
        "import cv2  # Python による「コンピュータビジョン(Computer Vision)」のためのライブラリ OpenCV のパッケージをインポート\n",
        "\n",
        "# 顔検出器の準備\n",
        "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次の3つのセルではあとで使う関数を定義しています．これらのセルを実行しただけでは何も起こりませんが，あらかじめ実行して関数を定義しておかないと後のセルが動きません．"
      ],
      "metadata": {
        "id": "Mb_MCcgrV6Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab へのファイルアップロードを実行する関数\n",
        "#\n",
        "def uploadToColab():\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        rv = files.upload()\n",
        "    except:\n",
        "        print('このコードは Colab 以外の環境では実行できないよ．')\n"
      ],
      "metadata": {
        "id": "yaET5ayh2QHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenCVの形式の画像を表示する関数\n",
        "#\n",
        "def imshow(img):\n",
        "    try:\n",
        "        from google.colab.patches import cv2_imshow\n",
        "        cv2_imshow(img) # Colab上で実行している場合\n",
        "    except:\n",
        "        cv2.imshow(img)  # それ以外の場合"
      ],
      "metadata": {
        "id": "5MrCNq0P2Oat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 与えられた画像の中から顔を検出する\n",
        "#\n",
        "def faceDetector(img, faceCascade, maxSize=400):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # (短辺の長さ) <= maxSize にリサイズ\n",
        "    if min(w, h) > maxSize:\n",
        "        if w <= h:\n",
        "            w2, h2 = maxSize, h*maxSize//w\n",
        "        else:\n",
        "            w2, h2 = w*maxSize//h, maxSize\n",
        "        imgDisp = cv2.resize(img, (w2, h2))\n",
        "    else:\n",
        "        imgDisp = np.copy(img)\n",
        "\n",
        "    # 顔検出を実行\n",
        "    imgGray = cv2.cvtColor(imgDisp, cv2.COLOR_BGR2GRAY)\n",
        "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
        "    nFace = len(faces)\n",
        "\n",
        "    # 検出した顔のうち最初のひとりを選んで切り取り\n",
        "    if nFace > 0:\n",
        "        print(faces)\n",
        "        x, y, ww, hh = faces[0]\n",
        "        imgFace = np.copy(imgDisp[y:y+hh, x:x+ww, :])\n",
        "        cv2.rectangle(imgDisp, (x, y), (x+ww, y+hh), color=(0, 255, 0), thickness=2)\n",
        "        return nFace, imgDisp, imgFace\n",
        "    else:\n",
        "        return nFace, imgDisp, None\n"
      ],
      "metadata": {
        "id": "4FKC12T0Wt6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathbf{w}$ などのパラメータを読み込みます．"
      ],
      "metadata": {
        "id": "FZ5QS0bqZkNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# takataka のウェブサイトからパラメータを格納したファイルを Colab へダウンロード\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/ageestimation.npz\n",
        "\n",
        "import os\n",
        "path = 'ageestimation.npz'\n",
        "if os.path.exists(path):\n",
        "    # パラメータを読み込む\n",
        "    params = np.load(path)\n",
        "    print(f'ファイル {path} を読み込みました')\n",
        "    Xm  = params['Xm']  # 平均ベクトル\n",
        "    eve = params['eve'] # 主成分分析で得られた固有ベクトル\n",
        "    w   = params['w']   # 重回帰分析で得られたパラメータ\n",
        "    print(Xm.shape, eve.shape, w.shape)\n",
        "else:\n",
        "    print(f'ファイル {path} の読み込みに失敗したようです．再実行してみてください')"
      ],
      "metadata": {
        "id": "XrD7wPFtZsba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験"
      ],
      "metadata": {
        "id": "Q8mhpECrY7K2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) 画像を Colab へアップロードします．次のような画像にしてください\n",
        "\n",
        "- ひとりのひとのほぼ正面を向いた顔全体が写ってる．複数人を検出した場合，ひとりだけ抜き出します（あとで条件に合わない画像をわざと与えて実験してみるのもよいでしょう）．\n",
        "- 画像全体に顔がドアップで写っているような場合はうまく顔検出ができないかもしれません．顔がもう少し小さく写ってる画像を探してみましょう．\n",
        "- ファイル名に空白やマルチバイト文字（日本語など）が含まれているとうまく動作しない場合があるので，自分のPCの方で適当な名前に変えておく（拡張子は変えてはいけない）．\n"
      ],
      "metadata": {
        "id": "GzHAoBgibuy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 以下の 0 を 1 に修正してセルを実行しよう\n",
        "#\n",
        "if 1 == 0:\n",
        "    # Colab へファイルをアップロード\n",
        "    uploadToColab()\n",
        "# ls コマンドでファイルを一覧\n",
        "! ls"
      ],
      "metadata": {
        "id": "8HMx-FEJY8Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上のセルを実行してファイルをアップロードできたら，次のセルのファイル名の部分にその名前を指定して，読み込ませましょう．"
      ],
      "metadata": {
        "id": "bd_gfEt5c8Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像を読み込む．`hoge.jpg` を自分がアップロードしたファイルの名前に修正\n",
        "img = cv2.imread('hoge.jpg')"
      ],
      "metadata": {
        "id": "DANLcHx5cl-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) 顔検出を実行して顔領域を切り取った画像を作る"
      ],
      "metadata": {
        "id": "7ggTCs3sdxjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numFace, imgDisp, imgFace = faceDetector(img, faceCascade, maxSize=400)\n",
        "if numFace > 0:\n",
        "    imshow(imgDisp)\n",
        "    imshow(imgFace)\n",
        "else:\n",
        "    imshow(imgDisp)\n",
        "    print('顔を検出できませんでした')"
      ],
      "metadata": {
        "id": "GOdtTrsNdwWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 顔を所定の大きさにリサイズしてから次元削減し，年齡推定を実行．"
      ],
      "metadata": {
        "id": "U5-5lzO3exb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 顔画像を 64 x 64 にリサイズして 12288次元ベクトルに\n",
        "xvec = cv2.resize(imgFace, (64, 64)).reshape(-1)\n",
        "print(xvec.shape)\n",
        "\n",
        "# PCAを利用した次元削減\n",
        "yvec = (xvec - Xm) @ eve\n",
        "print(yvec.shape)\n",
        "\n",
        "# 予測値の計算\n",
        "yvec1 = np.concatenate(([1], yvec)) # 先頭に 1 をくっつける\n",
        "z = w @ yvec1\n",
        "\n",
        "# 結果の表示\n",
        "print(f'このひとの年齡の推定値は {z:.1f} です')"
      ],
      "metadata": {
        "id": "MBsghH-QeP0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 解説"
      ],
      "metadata": {
        "id": "5qyXn1jghgyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この年齡推定の仕組みは，次のようにして作りました．以下のうち，(3), (4), (5) ではデータの次元を削減するために主成分分析を実行しています．次元削減や主成分分析については，「多変量解析及び演習」で登場していますので，興味のある方は [2023年度「多変量解析及び演習」](https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2023) へどうぞ．「機械学習II」でも登場する予定です．\n",
        "\n",
        "(1) [IMDB-WIKI dataset](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/) という研究用画像データセットの中に，Wikipedia から集めた顔画像とその性別，生年月日，撮影年などが含まれたデータ（画像 62,328枚）があったので，これを利用．\n",
        "\n",
        "(2) 生年月日と撮影年から年齡を算出．顔がちゃんと写ってなかったり年齡の推定値がおかしかったりするデータを削除．顔の領域のみを抜き出す．得られた画像は 38138 枚．この前処理の部分では，こちらのサイトを参考にさせてもらいました：\n",
        "[顔画像から年齢・性別を推定するためのデータセットIMDB-WIKI](https://qiita.com/yu4u/items/a2410f46669c5f20ee8e)"
      ],
      "metadata": {
        "id": "ziXmznu4h4wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 得られた画像を $64\\times 64$ に縮小してデータ行列 `X` を作成．\n",
        "`X.shape` は `(38138, 12288)`．"
      ],
      "metadata": {
        "id": "mGKKh8J3j9vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) `X` の平均を求めてこれを `X` から引き，特異値分解経由で主成分分析のための固有値・固有ベクトルを算出．次のスペックの Mac で `np.linalg.svd` の実行に23分．\n",
        "- CPU: Apple M1 Pro\n",
        "- メモリ: 32GB"
      ],
      "metadata": {
        "id": "FXR-Wg_0kmcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(5) 累積寄与率を調べると，2151次元ではじめて99%を超えていたので，2151次元に次元削減した．"
      ],
      "metadata": {
        "id": "78jGaFvClAnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(6) そのデータを用いて最小二乗法の解を計算．上記の Mac で `np.linalg.lsesq` の実行に 28 秒．"
      ],
      "metadata": {
        "id": "418_rDV4lYXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(7) `X` の平均（12288次元），固有ベクトル（12288x2151），重回帰のパラメータ（2152次元）をファイルに保存．"
      ],
      "metadata": {
        "id": "b8lu3PXOlwzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "また，前処理として画像の中から顔を検出する処理も行っています．こちらは，「コンピュータビジョン(Computer Vision)」のためのライブラリ OpenCV の中にある顔検出ライブラリを使っています．\n",
        "これは，画像を顔とそれ以外のものの2つに分類する仕組みで，やはり機械学習の方法で作られています．"
      ],
      "metadata": {
        "id": "yOJIeGno9Q_O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ptfMY6UigZdB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
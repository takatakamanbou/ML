{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2025/ML2025_ex03notebookB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex03notebookB\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2025)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## 識別のための教師あり学習(2) 最近傍法と $k$-近傍法\n",
        "----\n",
        "\n",
        "<b><font color=\"#ff0000\">\n",
        "注意:\n",
        "今回の notebook の中には，コードセルを実行すると問題の解答が表示されるようになっている箇所があります．\n",
        "</font>\n",
        "</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glgWbdlh34P"
      },
      "source": [
        "----\n",
        "### 準備\n",
        "\n",
        "\n",
        "以下，コードセルを上から順に実行してながら読んでいってね．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set_theme()\n",
        "\n",
        "# 「解答」を示す際に文字列を復号するのに使う\n",
        "import base64\n",
        "# 復号した文字列を Markdown 形式で（数式は LaTeX でフォーマットして）表示\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTzvMDtLiyg5"
      },
      "source": [
        "----\n",
        "### 例題: 人間 vs ほげ星人\n",
        "\n",
        "識別の問題について考える際の具体例として，「身長(cm)」と「体重(kg)」という二つの値から，「人間」と「ほげ星人」を識別する問題を考えます．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 「人間 vs ほげ星人」データの入手\n",
        "dfHoge = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/humanvshoge.csv', header=0)"
      ],
      "metadata": {
        "id": "ErefeHCWd61o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの中身はこんなん："
      ],
      "metadata": {
        "id": "8mSfFYyBd_iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfHoge"
      ],
      "metadata": {
        "id": "nKSzH91R0UmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1行がひとりぶんのデータ．'height' が身長，'weight'が体重，'label' が 'Human' なのは人間，'Hoge' なのはほげ星人，ということです．"
      ],
      "metadata": {
        "id": "YrWyXDmSnAGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データのうち (身長, 体重) の値を配列 X へ，クラスラベルを配列 Y へ\n",
        "X = dfHoge.loc[:, ['height', 'weight']]\n",
        "Y = dfHoge['label']\n",
        "X_human = X[Y=='Human'].to_numpy()\n",
        "X_hoge  = X[Y=='Hoge'].to_numpy()"
      ],
      "metadata": {
        "id": "o9hu5i2p0dgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 身長を横軸に，体重を縦軸にとって散布図を描く\n",
        "# 人間が青でほげ星人がオレンジ\n",
        "fig, ax = plt.subplots(facecolor=\"white\", figsize=(8, 8))\n",
        "ax.set_xlim(0,250)\n",
        "ax.set_xlabel('height [cm]')\n",
        "ax.set_ylim(0,150)\n",
        "ax.set_ylabel('weight [kg]')\n",
        "ax.set_aspect('equal')\n",
        "ax.scatter(X_human[:, 0], X_human[:, 1])\n",
        "ax.scatter(X_hoge[:, 0], X_hoge[:, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zs2OkY1l0Ltc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ひとりひとりが $(身長,体重)$ という二つの数値の組で表されていますので，これら二つの値で散布図を描いてみると，ひとりが一つの点に対応します．\n",
        "図の青い点が人間，オレンジの点がほげ星人（注）．\n",
        "\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: ここで扱っているデータは，架空のものです．説明を簡単にするために身長や体重の値を適当に設定しています．例題としての扱いを超えて，「身長や体重の値が〇〇だと人間ではない」というような主張をしているわけではありません．\n",
        "</span>"
      ],
      "metadata": {
        "id": "j6Z4z_iulqAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 最近傍法とは\n"
      ],
      "metadata": {
        "id": "N2TgMfBSsGhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**最近傍法** (Nearest Neighbor Method)は，識別の方法の一つです．\n",
        "**最短距離法** と同様に，データとデータの間の距離（注）に基づいて未知データのクラスを決定します．\n",
        "\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 距離の規準としては，一般的なユークリッド距離の他に，データの性質に応じて様々なものが用いられます．\n",
        "</span>"
      ],
      "metadata": {
        "id": "N-m8r8NtooDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最短距離法の手順は，こんなんでした：\n",
        "\n",
        "1. クラスごとに見本となるデータ（**プロトタイプ** (prototype)）を用意しておく．\n",
        "1. 所属クラスが未知のデータが与えられたら，そのデータがどのプロトタイプと近いかを調べる．\n",
        "1. 一番近いプロトタイプと同じクラスに分類する．\n"
      ],
      "metadata": {
        "id": "nHGxPQqJpMeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実は，上記の手順は最近傍法の手順にもなっています．ただし，最短距離法ではプロトタイプを一クラス一つしか用いませんでしたが，最近傍法では複数のプロトタイプを用います．\n",
        "一般的には，学習データとして用意されたデータを全てプロトタイプとして扱います．\n"
      ],
      "metadata": {
        "id": "Qi5ljaIEpWkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下に「人間 vs ほげ星人」の識別を最近傍法で行うプログラムを用意しました．学習データを全てプロトタイプとし，距離はユークリッド距離で測ります．"
      ],
      "metadata": {
        "id": "RaL_u-2Z0HW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 「人間 vs ほげ星人」最近傍法による識別実験のための関数\n",
        "#\n",
        "def hoge(X, Y, height, weight):\n",
        "\n",
        "    # 学習データ\n",
        "    X_human = X[Y=='Human'].to_numpy()\n",
        "    X_hoge  = X[Y=='Hoge'].to_numpy()\n",
        "\n",
        "    # 識別対象の身長と体重\n",
        "    x = np.array([height, weight])\n",
        "\n",
        "    # 最近傍のデータを見つける\n",
        "    d2 = np.sum((X - x)**2, axis=1) # 各データとの距離の2乗\n",
        "    imin = np.argmin(d2)  # 距離最小のデータの番号を求める\n",
        "    p_h, p_w, p_lab = X.iloc[imin, 0], X.iloc[imin, 1], Y.iloc[imin]\n",
        "    print(f'({x[0]}, {x[1]}) との距離が最小なのは{imin}番:({p_h}, {p_w})  クラスラベルは {p_lab}')\n",
        "\n",
        "    # グラフを描く\n",
        "    fig, ax = plt.subplots(facecolor=\"white\", figsize=(8, 8))\n",
        "    ax.set_xlim(0,250)\n",
        "    ax.set_xlabel('height [cm]')\n",
        "    ax.set_ylim(0,150)\n",
        "    ax.set_ylabel('weight [kg]')\n",
        "    ax.set_aspect('equal')\n",
        "    # 学習データの点を描く\n",
        "    ax.scatter(X_human[:, 0], X_human[:, 1])\n",
        "    ax.scatter(X_hoge[:, 0], X_hoge[:, 1])\n",
        "    # 識別対象の点を描く\n",
        "    ax.plot(x[0], x[1], marker='*', markersize=20, color='green')\n",
        "    # 識別対象とその最近傍の点の間に線分を引く\n",
        "    ax.plot([x[0], X.iloc[imin, 0]], [x[1], X.iloc[imin, 1]], linestyle='-', color='gray')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TBb5AixqsPD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title height，weightの値をいろいろ変えて実験しよう（値を変えたらセルの再実行忘れずに）\n",
        "height = 140.0 #@param {type:\"number\"}\n",
        "weight = 100.0 #@param {type:\"number\"}\n",
        "\n",
        "# (height, weight) のひとはどっち？\n",
        "hoge(X, Y, height, weight)"
      ],
      "metadata": {
        "id": "XcRe-Gexsy6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ★ やってみよう\n",
        "\n",
        "(1) $(\\textrm{height}, \\textrm{weight})$ の値をいろいろ変えて上記のセルを実行し，結果を観察しよう．\n",
        "\n",
        "(2) 以下のひとは人間と識別されるかほげ星人と識別されるかセルを実行して確認しよう．\n",
        "結果をノート等（紙媒体）にメモしておこう．\n",
        "\n",
        "- $(身長, 体重) = (150, 100)$ のひと\n",
        "- $(身長, 体重) = (130, 75)$ のひと\n",
        "- $(身長, 体重) = (130, 78)$ のひと\n",
        "\n",
        "(3) 以下の文中の箱の箇所に当てはまる数または語を答えなさい．\n",
        "> $(150, 100)$ との距離が最小なのは 121 番のデータ $\\left(\\fbox{A}, \\fbox{B}\\right)$ である．このデータは $\\fbox{C}$ クラスに属するので，$(150, 100)$ も $\\fbox{C}$ クラスに属すると予測される．"
      ],
      "metadata": {
        "id": "VDy3gKjXzr6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルを実行すると，上記の問に対する解答例が表示されます\n",
        "Q = b'CigxKSDnnIHnlaXvvI4KCigyKSDnnIHnlaXvvI4KCigzKSBBID0gMTU3LjksIEIgPSA4NC45LCBDID0g5Lq66ZaTCg=='\n",
        "display(Markdown(base64.b64decode(Q).decode('utf-8')))"
      ],
      "metadata": {
        "id": "epjiI0fastZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 最近傍法の性質\n",
        "\n"
      ],
      "metadata": {
        "id": "gD0NSihy5ydf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最短距離法では，二つのクラスを分ける識別境界は，2つのプロトタイプの垂直二等分線（より高次元では同様の平面）になるのでした．\n",
        "最近傍法の場合は，一つのクラスに複数のプロトタイプがあるため，識別境界はもっと複雑になります．\n",
        "\n",
        "下図左のような2次元3クラス（点の色がクラスを表します）のデータが与えられたときに，これらをプロトタイプとして，この平面上の各点を最近傍法で3クラスに分類して色を塗り分けると，下図右のようになります．\n",
        "プロトタイプの配置に応じて入り組んだ識別境界ができているのがわかりますね．"
      ],
      "metadata": {
        "id": "SAiZvfYGhz6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"75%\" src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/2dim3class3.png\">"
      ],
      "metadata": {
        "id": "xs4Irh3zjgut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "また，最近傍法を大規模なデータに適用したい場合は，その計算コスト（計算にかかる手間）にも気を配らねばなりません．\n",
        "機械学習では学習データの数が多い方がよい結果を得られやすいので，例えば画像を扱うような場合でも，その数が数万とか数百万とかになり得ます．このような大量のデータをすべてプロトタイプとして最近傍法を実行しようとすると，一つのデータの識別結果を得るために膨大な数のプロトタイプとの距離を計算することになり，現実的な時間で結果が得られなくなったりします（注）．\n",
        "\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 大規模なデータに対して最近傍法を適用したい場合，あらかじめ学習データの中からプロトタイプを選別するとか，最も距離の小さいデータを見つける処理（最近傍探索といいます）を効率よくまたは近似的に行う高速計算アルゴリズムを採用するとかします．\n",
        "</span>"
      ],
      "metadata": {
        "id": "Z0qZAbVzjNUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### $k$-近傍法"
      ],
      "metadata": {
        "id": "dsJ2u3BTsnXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**最近傍法** を拡張した識別手法に，**$k$-近傍法** ($k$-Nearest Neighbor Method)というものがあります．これは，次のようなものです．\n",
        "\n",
        "1. クラスごとに見本となるデータ（これを **プロトタイプ** (prototype）といいます）を用意しておく．\n",
        "1. 所属クラスが未知のデータが与えられたら，そのデータとの距離が小さい方から $k$ 個のプロトタイプを見つける．\n",
        "1. これらプロトタイプの所属クラスの多数決によって未知データの所属クラスを決定する．\n",
        "\n",
        "この説明からわかると思いますが，$k = 1$ の$k$-近傍法（$1$-近傍法）は最近傍法そのものです．\n",
        "下図に，2次元2クラスのデータ（赤と青の点）を用いて，$1$-近傍法と$7$-近傍法のそれぞれで平面を赤と青の2クラスに塗り分けたものを示します．\n",
        "$k=7$の方では，平面上の各点に入った赤青の票の数に応じて色の濃さを変えてあります．\n",
        "$k$ を大きくすることで，識別境界（赤と青の境目）が滑らかな形になっていることがわかります．"
      ],
      "metadata": {
        "id": "gEvyUexvlTQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"75%\" src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/knn.png\">"
      ],
      "metadata": {
        "id": "zl7WbRIQstTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この例でもわかるように，$k$-近傍法による識別の結果は $k$の値によって変わります．ですので，この $k$ もある意味パラメータのようなものです．\n",
        "しかし，一般的なパラメータと違い，学習の過程で自動的に決まったりはしません．\n",
        "通常は，人間があらかじめ適当に決めておきます．このように，機械学習モデルの中には，自動的に調節できないパラメータが存在する場合があります．\n",
        "このようなパラメータのことを，**ハイパーパラメータ** (Hyper Parameter) といいます．\n",
        "\n",
        "自動的に決められないとはいえ，ハイパーパラメータをいい加減に決めるのはよくありません．\n",
        "その辺りの話は，「機械学習II」の方で少し説明する予定です．"
      ],
      "metadata": {
        "id": "tkEacalpopRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 例題: 手書き数字の識別\n",
        "\n",
        "0 から 9 までの手書き数字の画像から，その画像に写っている数がいくつかを答えさせる問題を考えます．\n",
        "\n",
        "ここで扱うデータは，機械学習の分野で超有名な [MNIST](http://yann.lecun.com/exdb/mnist/) と呼ばれるデータセットからとったものです．\n",
        "MNIST のデータは学習用だけで6万枚の画像がありますので，そこからランダムに一部の画像を抽出したものを用意しました．\n"
      ],
      "metadata": {
        "id": "NmGsEm_pdysA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 手書き数字データの入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/minimnist.npz\n",
        "rv = np.load('minimnist.npz')\n",
        "datL = rv['datL'].astype(float)\n",
        "labL = rv['labL']\n",
        "datT = rv['datT'].astype(float)\n",
        "labT = rv['labT']\n",
        "print(datL.shape, labL.shape, datT.shape, labT.shape)\n",
        "\n",
        "K = 10 # クラス数\n",
        "D = datL.shape[1] # データの次元数 28 x 28 = 784"
      ],
      "metadata": {
        "id": "kLzbKM7DggvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のセルでは関数を定義しています．定義してるだけですので，このセルを実行しただけでは何も起こりません．"
      ],
      "metadata": {
        "id": "z4WqZnFjg8A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを画像として表示するための関数\n",
        "#\n",
        "def displayImage(data, nx, ny, nrow=28, ncol=28, gap=4):\n",
        "\n",
        "    assert data.shape[0] == nx*ny\n",
        "    assert data.shape[1] == nrow*ncol\n",
        "\n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype = int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        for ix in range(nx):\n",
        "            ltx = ix*(ncol + gap) + gap\n",
        "            img[lty:lty+nrow, ltx:ltx+ncol] = data[iy*nx+ix].reshape((nrow, ncol))\n",
        "\n",
        "    # 画像の出力\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "efKQJqzdfeTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習データ中の最初の50個の画像を表示．"
      ],
      "metadata": {
        "id": "0cwd0bIzhKFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx, ny = 10, 5\n",
        "display(datL[:50], nx, ny)"
      ],
      "metadata": {
        "id": "TbFPtvYygy13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "それぞれの正解クラスを表示．"
      ],
      "metadata": {
        "id": "EWrQulA7hp8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iy in range(ny):\n",
        "    print(labL[iy*nx:(iy+1)*nx])"
      ],
      "metadata": {
        "id": "skNX_p98hnEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 最近傍法による手書き数字の識別\n",
        "\n",
        "上記のデータに対して最近傍法を適用して識別させてみましょう．\n",
        "学習データすべてをプロトタイプとし，距離はユークリッド距離で測ることにします．\n"
      ],
      "metadata": {
        "id": "uPtzknwAmLYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは，学習データを識別させてみます．\n",
        "ただし本当は，学習データ全部をプロトタイプとした最近傍法の場合，学習データに対する識別はやってみるまでもありません．やらなくてもどういう結果になるか，正解率がいくつかはわかってます．どうしてか考えてみてね．\n",
        "\n",
        "次のセルは，実行に少し時間がかかります．先に説明した通り，距離の計算をたくさんやってるためです（注）．\n",
        "\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 実は，高校数学（ベクトルの性質）と少しのプログラミングの知識でもう少し効率のよい計算法を実装できるのですが，その辺はおまけ課題にする...かも．\n",
        "</span>"
      ],
      "metadata": {
        "id": "023rCDddoukg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データを識別\n",
        "N = len(datL)\n",
        "ncorrect = 0\n",
        "for n in range(N):\n",
        "    if n % 500 == 0:\n",
        "        print(f'{n}/{N}')\n",
        "    dist2 = np.sum((datL[n, :] - datL)**2, axis=1) # 各プロトタイプとの距離の2乗\n",
        "    out = labL[np.argmin(dist2)]  # 識別されたクラス\n",
        "    if out == labL[n]:  # 正解数をカウント\n",
        "        ncorrect += 1\n",
        "\n",
        "print(f'正解率: {ncorrect}/{N} = {ncorrect/N}')"
      ],
      "metadata": {
        "id": "ay1MILznnMWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次は，学習データとは別に用意したデータ（以下「テストデータ」と呼ぶことにします）を識別させてみます．"
      ],
      "metadata": {
        "id": "dPJF8HZJpUgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータを識別\n",
        "N = len(datT)\n",
        "out = np.empty(N, dtype=int)\n",
        "for n in range(N):\n",
        "    dist2 = np.sum((datT[n, :] - datL)**2, axis=1) # 各プロトタイプとの距離の2乗\n",
        "    out[n] = labL[np.argmin(dist2)]  # 識別されたクラス\n",
        "\n",
        "ncorrect = np.sum(out == labT) # 正解数をカウント\n",
        "\n",
        "print(f'正解率: {ncorrect}/{N} = {ncorrect/N}')"
      ],
      "metadata": {
        "id": "FRDwzrVDoRYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テストデータのうちいくつかについて，最も距離が小さいと判断されたプロトタイプの画像とそのクラスラベルを表示してみると...\n"
      ],
      "metadata": {
        "id": "iTFRMjCXJJw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datT の中からいくつか選択して識別結果を表示\n",
        "idx = np.array([5, 6, 7, 8, 9, 35, 36, 37, 38, 39])\n",
        "dat = datT[idx, :]\n",
        "N = len(dat)\n",
        "for n in range(N):\n",
        "    dist2 = np.sum((dat[n, :] - datL)**2, axis=1) # 各プロトタイプとの距離の2乗\n",
        "    out[n] = np.argmin(dist2)  # 距離最小のプロトタイプの番号\n",
        "\n",
        "displayImage(dat, N, 1)\n",
        "print('上記の画像の正解クラス番号:', labT[idx])\n",
        "displayImage(datL[out[:N], :], N, 1)\n",
        "print('最も近かったプロトタイプの画像とそのクラス番号:', labL[out[:N]])"
      ],
      "metadata": {
        "id": "T8o8lnpsA6EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ★ やってみよう\n",
        "\n",
        "1. 上記の実験の以下の記述のところ．考えてみてね．\n",
        "> ただし本当は，学習データ全部をプロトタイプとした最近傍法の場合，学習データに対する識別はやってみるまでもありません．やらなくてもどういう結果になるか，正解率がいくつかはわかってます．どうしてか考えてみてね．\n",
        "1. 上記の実験では，テストデータに対する正解率はいくつだったか．メモしておこう．\n",
        "1. 上記の実験では，正解のクラスが\n",
        "    > [6 9 7 9 1 6 0 5 7 6]\n",
        "\n",
        "    である10枚の画像たちを最近傍法で識別させた結果を表示しています．\n",
        "そのうち，識別結果が間違っていたものについて，「正解のクラスは〇だったが間違って●と識別していた」のようにメモしておきましょう．\n"
      ],
      "metadata": {
        "id": "DOEhSkbUqRjS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ffg0LHA1TLB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
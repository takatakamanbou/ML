{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2024/ML2024_ex07notebookB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex07notebookB\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## 事前学習済みモデルの利用\n",
        "----\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "近年のいわゆる人工知能（AI, Airtificial Intelligence）のシステムの裏には，ニューラルネットワークをはじめとする様々な機械学習の技術があります．難しい課題をこなせるようなシステムを作るためには，学習データを大量に用意して大規模な（パラメータ数が多く複雑な）モデルを学習させることが必要なわけですが，そのような学習をすべて自前でやろうとすると，多大な手間と時間がかかります．\n",
        "\n",
        "このような手間と時間を軽減する方法として，画像認識，音声認識，自然言語処理等の汎用性の高い問題を解くような学習モデルを，大量のデータを用いて事前に学習させておき，得られたモデルを個別の問題ごとに微調整して使う，というやり方がよく用いられます．"
      ],
      "metadata": {
        "id": "qOGaZ9WUEl5I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glgWbdlh34P"
      },
      "source": [
        "----\n",
        "### 1000種類の画像識別を学習済みのニューラルネットを動かしてみよう\n",
        "\n",
        "\n",
        "例として，VGG16 というニューラルネットワークの事前学習済みモデルを動かしてみます．VGG16は，イギリスオックスフォード大学の [Visual Geometry Group(VGG)](https://www.robots.ox.ac.uk/~vgg/) という研究グループが作った VGG-net というニューラルネットワークモデルのうちの，層が16層あるものです．\n",
        "VGG-net は，2014年に行われた [ILSVRC2014](https://www.image-net.org/challenges/LSVRC/2014/) という画像識別のコンペティションで世界第2位となったニューラルネットワークモデルです．\n",
        "ILSVRC2014では，[ImageNet](https://www.image-net.org/) という大規模な画像データセットの中から選ばれた 1000 種類の物体の画像約 120 万枚を学習データとしていました．\n",
        "\n",
        "参考文献: [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### 準備"
      ],
      "metadata": {
        "id": "AMXViIfIydTC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 準備その1: 実験に使う画像データの準備"
      ],
      "metadata": {
        "id": "P-AmCU9NCRGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**注意: 以下の画像をこの実験以外の目的で使用してはいけません**"
      ],
      "metadata": {
        "id": "2qJ5Zj6r8REl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/animalphoto.pickle\n",
        "with open('animalphoto.pickle', 'rb') as f:\n",
        "    hoge = pickle.load(f)\n",
        "\n",
        "imgList = []\n",
        "for d in hoge:\n",
        "    img = Image.frombytes(**d)\n",
        "    imgList.append(img)\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Io3_Xdj5NMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 準備その2: クラスの番号とクラスラベルの対応表の作成"
      ],
      "metadata": {
        "id": "dwjnxlnZqkSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageNet クラスラベルを表すJSONファイルを入手\n",
        "!wget -nc https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
        "class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
        "\n",
        "K = len(class_index)\n",
        "labels = {}\n",
        "for ik, key in enumerate(class_index.keys()):\n",
        "    labels[ik] = f'{class_index[key][0]} {class_index[key][1]}'\n",
        "    if 276 <= ik < 300:\n",
        "        print(ik, labels[ik])"
      ],
      "metadata": {
        "id": "-5nFrG_ywpOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の出力は，1000クラスのうちの一部のものの名前を表します．「ネコ」みたいなものも1クラスではなく，281番 'tabby'（ぶち柄の猫），282番 'tiger_cat'（トラ縞の猫）等々のように分かれています．"
      ],
      "metadata": {
        "id": "goVX8Ln9CZ-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 準備3: 事前学習済みニューラルネットのパラメータの入手\n",
        "\n",
        "規模の大きいネットワークでパラメータがたくさんありますので，読み込みに少し時間がかかります．"
      ],
      "metadata": {
        "id": "v0srx3ogtOaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = models.VGG16_Weights.IMAGENET1K_V1\n",
        "preprocess = weights.transforms()\n",
        "model = models.vgg16(weights=weights)\n",
        "model.eval()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "uLg8zK7HyDKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルを実行すると，次のことが行われます．\n",
        "1. VGG16のネットワークモデルを作成する．\n",
        "1. ImageNetで学習済みのパラメータの値を読み込んでこのネットワークのパラメータに設定する．\n",
        "1. ネットワークモデルの構造を表示する．\n",
        "\n",
        "画像を扱うニューラルネットでは，「畳み込み層」(convolutional layer)という特別な構造がよく用いられます．\n",
        "VGG16は，畳み込み層が13層（上記の出力の `Conv2d` というのが畳み込み層），全結合層（`Linear`，階層型ニューラルネットワークとして説明したものはこれ）3層の計16層から成っています（これ以外にもいくつか特殊な層が間に挟まってます）．"
      ],
      "metadata": {
        "id": "g-V8tZ5Atyqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### 実験1\n",
        "\n",
        "上記のサンプル画像たちを VGG16 で識別させてみましょう．\n"
      ],
      "metadata": {
        "id": "uyWss1-izFXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title サンプル画像の識別\n",
        "#@markdown 以下で 0 から 3 までの整数を選ぶと4つのサンプル画像の中から一つを選ぶことができます．\n",
        "i = 0 #@param [0, 1, 2, 3] {type: 'raw'}\n",
        "img = imgList[i]\n",
        "\n",
        "# 画像を表示\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(imgList[i]), axis=0)\n",
        "Y = model(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "9pp3WWir8sLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の画像の下の出力は，1000個のクラスの中で，ネットワークの出力の値が大きかったもの上位5位までの，出力の値とクラス名を表します．\n",
        "ネットワークの出力層の活性化関数は softmax ですので，出力の値は0から1でかつ1000子の出力の値すべての和が 1 となっています（一般のロジスティック回帰モデルの説明参照）．\n",
        "これらの値は，そのクラスと判定することの「確信度」と解釈できます．"
      ],
      "metadata": {
        "id": "-dKliElj-rnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### 実験2\n",
        "\n",
        "自分で用意した画像でも実験してみましょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "Ss4c8IAe_9Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) まずは，ウェブ等で適当な画像を探して手元に保存しましょう．JPEG（拡張子は `.jpg` や `.jpeg` 等）やPNG（`.png`）等の形式のものが扱えます．ファイル名が長かったり日本語を含んでいる場合は，短い名前に変更しておくのがよいです．\n",
        "\n",
        "(2) 以下のセルを実行して，ファイルをアップロードします．"
      ],
      "metadata": {
        "id": "Sii3vXZ8AU2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab へファイルをアップロード\n",
        "from google.colab import files\n",
        "rv = files.upload()\n",
        "\n",
        "# ファイル一覧\n",
        "! ls"
      ],
      "metadata": {
        "id": "o83_b8kY9_Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 以下のセルの1行目のファイル名を上記でアップロードしたものに変えて実行しましょう．アルファベット大文字小文字の区別もありますので注意．うまくいけば画像が表示されるはずです．"
      ],
      "metadata": {
        "id": "PHZCqDSHBiG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn = 'hoge.jpg' # ファイル名を変更しましょう\n",
        "\n",
        "myimg = Image.open(fn)\n",
        "if myimg.mode != 'RGB':\n",
        "    myimg = myimg.convert('RGB')\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(myimg)\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F72S_3eO9Ask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) 以下のセルを実行すれば結果が表示されます．"
      ],
      "metadata": {
        "id": "YGckmXO7Bzs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(myimg), axis=0)\n",
        "Y = model(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "u8vrSrciBbgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "実験1は動物の例ばかりでしたが，1000のクラスの中にはそれ以外にも様々なものがあります（「人間」を表すクラスはありません）．いろいろ試してみてください．面白い／不思議な結果が得られたら takataka に見せてくれると喜びます．\n"
      ],
      "metadata": {
        "id": "DcJkOJaq-PAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ファインチューニング\n",
        "\n",
        "notebook の冒頭でも説明したように，機械学習モデルを一から学習させるには手間と時間がかかります．そのため，自分が扱うタスク（課題）でモデルを一から学習させるかわりに，類似のタスクで学習済みのモデル（事前学習済みモデル）を入手して，そのモデルを自分のタスク向けに微調整して使うことがよくあります．この微調整のことを **ファインチューニング**(fine-tuning) といいます．\n"
      ],
      "metadata": {
        "id": "C7mXHlG7rK6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前学習済みのニューラルネットをファインチューニングするには，典型的には次のような手順をとります（下図参照）．\n",
        "\n",
        "1. 自分のタスクと類似したタスクで学習済みの事前学習済みモデルを入手する．↑の VGG16 は，画像認識をやりたい場合に使える事前学習済みモデルの一例です．\n",
        "1. 入手したモデルの出力側の一部を自分のタスクに合わせて新規に作り直し，自分の用意したデータでモデルを学習させる．このとき，パラメータを修正するのは新規に用意した部分のみとし，入力側のパラメータは事前学習済みモデルのものに固定しておく（注）．\n",
        "\n",
        "※注: 事前学習モデルのパラメータを初期値として，入力側のパラメータも含めてモデル全体を学習させることもよくあります．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/transferlearning.png\">"
      ],
      "metadata": {
        "id": "vE_Km02ArQNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このような方法を採ることには，次のようなメリットがあります．\n",
        "\n",
        "1. 大きなニューラルネットを一から学習させずに済むので，学習にかける手間と時間を軽減できる．\n",
        "1. 少ないデータで大きなニューラルネットを一から学習させると過適合の心配があるが，このような方法を採ることで過適合を避けて識別率等の性能の高いモデルを得やすい．\n",
        "1. 大規模データで学習した事前学習済みモデルは，その入力側の部分が特徴抽出の仕組みとして汎化性能の高い優れたものになっていることが多い．それを流用できるので，ファインチューニングしたモデルも高い性能を期待できる．\n",
        "\n",
        "例えば，VGG16 のような事前学習済みモデルをファインチューニングすることで，新たな画像認識タスクを解く高性能なニューラルネットを手軽に作ることができます．"
      ],
      "metadata": {
        "id": "5sEXW3eks-ET"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mS6YWH13XOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
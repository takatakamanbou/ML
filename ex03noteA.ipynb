{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/main/ex03noteA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex03noteA\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2022)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glgWbdlh34P"
      },
      "source": [
        "----\n",
        "## 準備\n",
        "----\n",
        "\n",
        "Google Colab の Notebook では， Python というプログラミング言語のコードを動かして計算したりグラフを描いたりできます．\n",
        "Python は，機械学習・人工知能やデータサイエンスの分野ではメジャーなプログラミング言語ですが，それを学ぶことはこの授業の守備範囲ではありません．以下の所々に現れるプログラムっぽい記述の内容は，理解できなくて構いません．\n",
        "\n",
        "以下，コードセルを上から順に実行してながら読んでいってね．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# データを読み込む\n",
        "dfGori = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/gorigori.csv', header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfD2FEfXh34O"
      },
      "source": [
        "----\n",
        "## 汎化と過適合\n",
        "----\n",
        "\n",
        "機械学習において，入力されたデータから予測値を出力する仕組みのことを **モデル** (model)と言います．\n",
        "直線当てはめにおける式 $y = ax+b$（パラメータは $a$と $b$） や平面当てはめにおける $y = w_0 + w_1x_1 + w_2x_2 + \\cdots + w_Dx_D$ （パラメータは $w_0, w_1, \\ldots , w_D$）などはモデルを表す式です．\n",
        "\n",
        "\n",
        "これまで説明してきた問題では，モデルが学習データによくよてはまるようにパラメータを決めていました．このこと自体はまっとうなことです．しかし，実際の機械学習の問題では，「学習データによくあてはまる」ことだけを考えていると，おかしな結果を得てしまうことがあります．そのことを理解するために，曲線への当てはめの問題を例にあげて説明します．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4RlkyhP5yo"
      },
      "source": [
        "----\n",
        "### 多項式当てはめ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "直線当てはめでは，モデルとして $y = ax+b$ という直線の式を仮定しています．\n",
        "二つの変数の間の関係がもっと複雑な場合には，直線当てはめではうまくいきません．\n",
        "試しに，本当は $y = \\cos{x}$ という関係にあるようなデータに対して最小二乗法で直線を当てはめてみると，こんなんなります．"
      ],
      "metadata": {
        "id": "j-s6pH4XJAeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを用意\n",
        "X = np.linspace(-3, 4, 8)\n",
        "Y = np.sin(X)  # 真の関係は y = sin(x)\n",
        "XX = np.vstack([X, np.ones_like(X)]).T\n",
        "xmin, xmax = -4.5, 5.5\n",
        "\n",
        "# 直線当てはめの最小二乗法\n",
        "XTX = XX.T @ XX  # 正規方程式左辺の 2x2 行列\n",
        "XTY = XX.T @ Y   # 正規方程式右辺の ベクトル\n",
        "a, b = np.linalg.solve(XTX, XTY)\n",
        "\n",
        "# 直線の式を計算\n",
        "Xr =  np.linspace(xmin, xmax, 100)\n",
        "Yest = a * Xr + b\n",
        "Ytru = np.sin(Xr)\n",
        "\n",
        "# グラフを描く\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(6, 4))\n",
        "ax.scatter(X, Y)\n",
        "ax.plot(Xr, Yest, color='red')\n",
        "ax.plot(Xr, Ytru, color='gray')\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(-1.5, 1.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BS_mCKF4XO4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "灰色の曲線が $y = \\cos{x}$，青い8つの点が学習データ，赤い直線が最小二乗法で得られた直線です．\n",
        "当たり前ですがぜんぜんうまく当てはまってませんね．\n",
        "\n",
        "このような場合への対応策の一つとして，直線のかわりに多項式を当てはめる方法があります．\n",
        "以下にその問題設定を示します．"
      ],
      "metadata": {
        "id": "b1hyjM-3ayH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**［最小二乗法による多項式当てはめの問題設定］**\n",
        "\n",
        "変数 $x$ と $y$ の値のペア $N$ 組から成るデータ\n",
        "$$\n",
        "(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\n",
        "$$\n",
        "がある．変数 $x$ の値から $y$ の値が決まるものとし，そのモデルとして $(D+1)$ 個のパラメータをもつ $D$ 次多項式\n",
        "\n",
        "$$\n",
        "y = f(x) = w_0 + w_1 x + w_2x^2 + \\cdots + w_Dx^{D} \\qquad (1)\n",
        "$$\n",
        "\n",
        "を考える．\n",
        "\n",
        "\n",
        "このとき，モデルの出力 $f(x_n)$ とその正解の値 $y_n$ との間の二乗誤差の和\n",
        "$$\n",
        "\\sum_{n=1}^{N}(y_n - f(x_n))^2\n",
        "$$\n",
        "を最小にするパラメータ $w_0, w_1, \\ldots, w_D$ を求めたい．\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "BSD8USkbK3jD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここから先は，正規方程式を導出 → その解が求めるパラメータ，ということで，これまでと同様です．\n",
        "実は，この多項式当てはめの問題は平面当てはめの問題をちょこっと変形したものとみなせます．\n",
        "\n",
        "平面当てはめでは，$1, x_1, x_2, \\ldots, x_D$ という $(D+1)$ 個の値をならべた $(D+1)$ 次元ベクトル\n",
        "$$\n",
        "\\mathbf{x} = (1, x_1, x_2, \\ldots, x_D)\n",
        "$$\n",
        "を考えましたが，そのかわりに\n",
        "$$\n",
        "\\mathbf{x} = (1, x^2, x^3, \\ldots, x^D)\n",
        "$$\n",
        "としてやれば ok，というわけです．こうすれば，平面当てはめと同様に$(D+1)$個のパラメータをならべたベクトルを\n",
        "$$\n",
        "\\mathbf{w} = (w_0, w_1, w_2, \\ldots, w_D)\n",
        "$$\n",
        "として，式(1)を\n",
        "$$\n",
        "y = f(\\mathbf{x}) = \\mathbf{w}\\cdot\\mathbf{x} \\qquad (2)\n",
        "$$\n",
        "と表せます．以下，平面当てはめの定式化と同じですので，正規方程式も同じ形になります．\n"
      ],
      "metadata": {
        "id": "xrIKO0QWGZtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の $\\cos{x}$ の例で試しにやってみると，以下のようになります．\n"
      ],
      "metadata": {
        "id": "wrb30mggY_FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 多項式の次数 D をいろいろ変えてこのセルを何度か実行し直してみよう {run: \"auto\"}\n",
        "D = 1 #@param{type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "# データを用意\n",
        "X = np.linspace(-3, 4, 8)\n",
        "Y = np.sin(X)  # 真の関係は y = sin(x)\n",
        "XX = np.ones((D+1, len(X)))\n",
        "for d in range(D):\n",
        "    XX[d+1, :] = X ** (d+1)\n",
        "xmin, xmax = -4.5, 5.5\n",
        "\n",
        "# 多項式当てはめの最小二乗法\n",
        "XXT = XX @ XX.T  # 正規方程式左辺の行列\n",
        "XYT = XX @ Y   # 正規方程式右辺のベクトル\n",
        "w = np.linalg.solve(XXT, XYT)\n",
        "print(f'{D}次多項式の当てはめ．')\n",
        "print(f'{len(w)}個のパラメータの値: ', end=' ')\n",
        "print(w)\n",
        "sqe = np.sum(np.square(Y - w @ XX))\n",
        "print(f'学習データに対する二乗誤差の和: {sqe:.6f}')\n",
        "\n",
        "# 直線の式を計算\n",
        "Xr =  np.linspace(xmin, xmax, 100)\n",
        "XXr = np.ones((D+1, len(Xr)))\n",
        "for d in range(D):\n",
        "    XXr[d+1, :] = Xr ** (d+1)\n",
        "Yest = w @ XXr\n",
        "Ytru = np.sin(Xr)\n",
        "\n",
        "# グラフを描く\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(6, 4))\n",
        "ax.scatter(X, Y)\n",
        "ax.plot(Xr, Yest, color='red', label=f'D = {D}')\n",
        "ax.plot(Xr, Ytru, color='gray')\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(-3, 3)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sKFQALJYbZeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "多項式の次数を上げるとだんだん二乗誤差の和が小さくなっており，学習データに対する当てはまりが良くなっていることがわかります．\n",
        "\n",
        "この結果を見る限りでは，「多項式当てはめでは，次数を大きくするほど複雑な関係を表せる．だから次数を大きくすればするほどよい」と思えるわけですが，本当にそう思ってよいでしょうか？\n",
        "「学習データ」への当てはまりはたしかによくなっており，学習データに対する二乗誤差の和も小さくなっていっています．しかし，学習データ以外のところではどうでしょうか？"
      ],
      "metadata": {
        "id": "lvi6bT7LZjds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 汎化と過適合\n",
        "\n",
        "もう少し次数を大きくして上記の実験を続けてみましょう．\n"
      ],
      "metadata": {
        "id": "NH-Y5YJTgBSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 多項式の次数 D をいろいろ変えてこのセルを何度か実行し直してみよう {run: \"auto\"}\n",
        "D = 8 #@param{type:\"slider\", min:8, max:20, step:1}\n",
        "\n",
        "# データを用意\n",
        "X = np.linspace(-3, 4, 8)\n",
        "Y = np.sin(X)  # 真の関係は y = sin(x)\n",
        "XX = np.ones((D+1, len(X)))\n",
        "for d in range(D):\n",
        "    XX[d+1, :] = X ** (d+1)\n",
        "xmin, xmax = -4.5, 5.5\n",
        "\n",
        "# 多項式当てはめの最小二乗法\n",
        "XXT = XX @ XX.T  # 正規方程式左辺の行列\n",
        "XYT = XX @ Y   # 正規方程式右辺のベクトル\n",
        "w = np.linalg.solve(XXT, XYT)\n",
        "print(f'{D}次多項式の当てはめ．')\n",
        "print(f'{len(w)}個のパラメータの値: ', end=' ')\n",
        "print(w)\n",
        "sqe = np.sum(np.square(Y - w @ XX))\n",
        "print(f'学習データに対する二乗誤差の和: {sqe:.6e}')\n",
        "\n",
        "# 直線の式を計算\n",
        "Xr =  np.linspace(xmin, xmax, 100)\n",
        "XXr = np.ones((D+1, len(Xr)))\n",
        "for d in range(D):\n",
        "    XXr[d+1, :] = Xr ** (d+1)\n",
        "Yest = w @ XXr\n",
        "Ytru = np.sin(Xr)\n",
        "\n",
        "# グラフを描く\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(6, 4))\n",
        "ax.scatter(X, Y)\n",
        "ax.plot(Xr, Yest, color='red', label=f'D = {D}')\n",
        "ax.plot(Xr, Ytru, color='gray')\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(-3, 3)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1eDBQ9FhUfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "すると，「学習データ（青い点）への当てはまりはよいのに，それ以外のところで真の関数（灰色）とは大きくずれてしまう」ようになっていることに気づきます．\n",
        "学習データに対しては $y$ の値を正確に予測できているが，学習データとは異なる $x$ の値に対しては $y$ の値をうまく予測できていないわけです．\n",
        "\n",
        "これでは困りますね．教師あり学習の場合，学習データは $(入力, それに対する出力の正解)$ というペアを集めたものです．それらを使ってモデルのパラメータを決めているわけですから，学習データに対して正解できるのは当然とも言えます．むしろ，学習時に見たことがない入力に対しても望ましい出力をできることの方が大事でしょう．"
      ],
      "metadata": {
        "id": "O7pVY_-Ih83N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ということで，機械学習においては，「学習データに対して望ましい出力ができるように」するだけでなく，「学習時に与えられていない未知のデータに対しても望ましい出力ができるように」することが目標となります．\n",
        "未知のデータに対しても望ましい出力ができることを， 「未知データに**汎化** (generalization) できる」とか「**汎化性能** が高い」というふうに言います．\n",
        "\n",
        "未知データは学習時には未知なものですから，それを使ってパラメータを調節することは当然できません．\n",
        "機械学習の目標は，「学習データを用いて，未知データに対してもなるべく汎化できるようなパラメータを求めること」と言えます．"
      ],
      "metadata": {
        "id": "1bglNA8HnjMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "また，多項式当てはめの例では，多項式の次数を増やす = パラメータの数を増やすと，より複雑な関数，より複雑なモデルを作ることができます．ですが，パラメータ数を増やせばよいかというと必ずしもそうではなく，パラメータを増やすと学習データにぴったり当てはまようになるるものの，汎化性能はむしろ低下しているようです．このように，パラメータ数の多いモデルが学習データに適合しずぎて汎化性能が低下してしまう現象を，**過適合**(over-fitting) または **過学習** と言います．\n",
        "\n",
        "<img width=\"50%\" src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/modeldof.png\">"
      ],
      "metadata": {
        "id": "iPtSD9Okw4GL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ゴリゴリ君のデータに対しても多項式当てはめやってみましょう．\n",
        "次数を大きくしていくと，学習データにうまく当てはまろうとぐにゃぐにゃしすぎて（学習データに過適合して），気温とアイス売上数の関係としてはおかしなものになっていってしまう（汎化性能が低下してしまう）のが見えるでしょう．"
      ],
      "metadata": {
        "id": "0m_ZAGLHyegG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 多項式の次数 D をいろいろ変えてこのセルを何度か実行し直してみよう {run: \"auto\"}\n",
        "D = 1 #@param{type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# データを用意\n",
        "X = dfGori['気温']\n",
        "Y = dfGori['アイス売上数']\n",
        "XX = np.ones((D+1, len(X)))\n",
        "for d in range(D):\n",
        "    XX[d+1, :] = X ** (d+1)\n",
        "xmin, xmax = -5, 40\n",
        "\n",
        "# 多項式当てはめの最小二乗法\n",
        "XXT = XX @ XX.T  # 正規方程式左辺の行列\n",
        "XYT = XX @ Y   # 正規方程式右辺のベクトル\n",
        "w = np.linalg.solve(XXT, XYT)\n",
        "print(f'{D}次多項式の当てはめ．')\n",
        "print(f'{len(w)}個のパラメータの値: ', end=' ')\n",
        "print(w)\n",
        "sqe = np.sum(np.square(Y - w @ XX))\n",
        "print(f'学習データに対する二乗誤差の和: {sqe:.6e}')\n",
        "\n",
        "# 直線の式を計算\n",
        "Xr =  np.linspace(xmin, xmax, 100)\n",
        "XXr = np.ones((D+1, len(Xr)))\n",
        "for d in range(D):\n",
        "    XXr[d+1, :] = Xr ** (d+1)\n",
        "Yest = w @ XXr\n",
        "Ytru = np.sin(Xr)\n",
        "\n",
        "# グラフを描く\n",
        "fig, ax = plt.subplots(1, facecolor='white', figsize=(6, 4))\n",
        "ax.scatter(X, Y)\n",
        "ax.plot(Xr, Yest, color='red', label=f'D = {D}')\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_ylim(-10, 140)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7AyJe9gnylXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは多項式当てはめの例で説明しましたが，過適合と汎化の問題は，機械学習の様々な場面で起こり得るものです．\n",
        "一般に，パラメータ数の多いモデルほど複雑な入出力関係を表現できます．\n",
        "モデルがデータに合わなかったりパラメータが少なすぎたりすると学習データにうまく当てはめることができません．\n",
        "一方，モデルのパラメータ数を多くすると，学習データにはうまく当てはまるようになります．\n",
        "しかし，あまりにパラメータ数が多いと，学習データに過適合して未知データにうまく汎化できない結果となる場合があります．\n",
        "\n",
        "<img width=\"50%\" src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/modeldof.png\">\n"
      ],
      "metadata": {
        "id": "KiRTUuA9qfLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "じゃあパラメータの数をどう決めたらいいの？という疑問が生じますが，残念ながら，どんな場合にもこれで解決，というような万能の解決法はありません．\n",
        "いくつかの対処法を「機械学習II」の方で説明します．"
      ],
      "metadata": {
        "id": "pOMDLm_V-ax7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xficxQe31VC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ex03noteA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
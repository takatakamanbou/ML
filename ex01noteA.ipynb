{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/main/ex01noteA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML2022 ex01noteA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/Data-logo15.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?Data/2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4-TmUdCd9FJ"
      },
      "source": [
        "## 準備\n",
        "\n",
        "Google Colab の Notebook では， Python というプログラミング言語のコードを動かして計算したりグラフを描いたりもできます．\n",
        "Python は，データ分析や機械学習・人工知能分野ではメジャーなプログラミング言語ですが，それを学ぶことはこの授業の守備範囲ではありません．ですので，以下の所々に現れるプログラムっぽい記述の内容は，理解できなくて構いません．\n",
        "\n",
        "以下，コードセルを上から順に実行していってね．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ8M3640S1W7"
      },
      "outputs": [],
      "source": [
        "# 科学技術計算のライブラリ NumPy のモジュールを np という名前で使えるようにする\n",
        "import numpy as np\n",
        "\n",
        "# グラフを描くためのライブラリ matplotlib の pyplot を plt という名前でインポート\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# コンピュータビジョン・画像処理のためのライブラリ OpenCV のモジュール cv2 をインポート\n",
        "import cv2\n",
        "\n",
        "# 深層学習のためのライブラリ Keras のいろいろ\n",
        "#import keras\n",
        "from tensorflow import keras\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# 時間計測のためのほげ\n",
        "import datetime\n",
        "\n",
        "# notebook 上で画像を表示するためのほげ\n",
        "from IPython.display import display, Image\n",
        "\n",
        "### 画像表示用の関数\n",
        "#\n",
        "def displayImage(img):\n",
        "    \n",
        "    if type(img) is np.ndarray:               # 渡されたのが np.ndarray だった（OpenCVの画像はこの形式)\n",
        "        rv, buf = cv2.imencode('.png', img)  # PNG形式のバイト列に変換\n",
        "        if rv:\n",
        "            display(Image(data = buf.tobytes()))   # 変換できたらバイト列を渡して表示\n",
        "            return\n",
        "    elif type(img) is str:                         # 渡されたのが文字列だった\n",
        "        display(Image(filename = img))\n",
        "        return\n",
        "    \n",
        "    print('displayImage: error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H45eNIcd2xB"
      },
      "source": [
        "----\n",
        "## 多変量解析や機械学習に関するデモ\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4RlkyhP5yo"
      },
      "source": [
        "----\n",
        "### クラスター分析／クラスタリング\n",
        "\n",
        "**クラスター分析**／**クラスタリング** は，多変量データをクラスタ分けする（似たもの同士でグループに分ける）ための手法です．\n",
        "\n",
        "ここでは，「K-means法（K-平均法）」と呼ばれるアルゴリズムを使って，猫の画像をクラスタリングしてみましょう．まずは，データやプログラムの準備を．以下のセルたちを順次実行してください．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnqr_MVSXeFT"
      },
      "source": [
        "(1) 猫画像データを入手します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DZPnNd2WxEi"
      },
      "outputs": [],
      "source": [
        "### 猫画像データを入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/PIP/cat131.npz\n",
        "cat = np.load('cat131.npz')['cat131']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSq_0oSXaFq"
      },
      "source": [
        "(2) 学習などのための関数を定義します．このセルは関数を定義するだけなので，実行しても何も出力されないのが正常です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpyiHu5dW2aC"
      },
      "outputs": [],
      "source": [
        "### セントロイドの初期化\n",
        "#\n",
        "def initCentroid(X, K):\n",
        "    idx = np.random.permutation(X.shape[0])[:K]\n",
        "    return X[idx, :]\n",
        "\n",
        "### 最も近いセントロイドの番号を求める\n",
        "#\n",
        "def compIndex(X, centroid, index):\n",
        "    for i, x in enumerate(X):\n",
        "        d2 = np.sum((x[np.newaxis, :] - centroid )**2, axis = 1)\n",
        "        index[i] = np.argmin(d2)\n",
        "\n",
        "### セントロイドを求める\n",
        "#\n",
        "def compCentroid(X, centroid, index):\n",
        "    for ik in range(centroid.shape[0]):\n",
        "        centroid[ik] = np.mean(X[index == ik, :], axis = 0)\n",
        "\n",
        "### コストおよびクラスタごとの所属データ数を求める\n",
        "#\n",
        "def compCost(X, centroid, index):\n",
        "    cost = 0.0\n",
        "    Nc = np.empty(centroid.shape[0], dtype = int)\n",
        "    for ik in range(centroid.shape[0]):\n",
        "        idx = index == ik\n",
        "        cost += np.sum((X[idx, :] - centroid[ik, np.newaxis, :] )**2)\n",
        "        Nc[ik] = np.sum(idx)\n",
        "    return cost / (X.shape[0] * X.shape[1]), Nc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gQB5oKgXTGH"
      },
      "source": [
        "(3) 可視化のための関数を定義します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hqS3DxeXN7x"
      },
      "outputs": [],
      "source": [
        "###  データの最初の nx x ny 枚を可視化\n",
        "#\n",
        "def mosaicImage(dat, nx, ny, nrow = 64, ncol = 64, gap = 4):\n",
        "\n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype = int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        for ix in range(nx):\n",
        "            if iy*nx+ix >= dat.shape[0]:\n",
        "                break\n",
        "            ltx = ix*(ncol + gap) + gap\n",
        "            img[lty:lty+nrow, ltx:ltx+ncol] = dat[iy*nx+ix, :].reshape((nrow, ncol))\n",
        "            \n",
        "    return img\n",
        "\n",
        "\n",
        "###  セントロイドとともにデータの最初の n 枚を可視化\n",
        "#\n",
        "def mosaicImage2(X, centroid, index, n, nrow = 64, ncol = 64, gap = 4):\n",
        "\n",
        "    nx = n + 2\n",
        "    ny = centroid.shape[0]\n",
        "    \n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype = int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        ix = 0\n",
        "        ltx = ix*(ncol + gap) + gap\n",
        "        img[lty:lty+nrow, ltx:ltx+ncol] = centroid[iy, :].reshape((nrow, ncol))\n",
        "        dat = X[index == iy, :]\n",
        "        for ix in range(2, nx):\n",
        "            jx = ix - 2\n",
        "            if jx >= dat.shape[0]:\n",
        "                break\n",
        "            ltx = ix*(ncol + gap) + gap\n",
        "            img[lty:lty+nrow, ltx:ltx+ncol] = dat[jx, :].reshape((nrow, ncol))\n",
        "            \n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPzZT55NXk9I"
      },
      "source": [
        "(4) 入手した猫画像の一部を表示してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohpbSSjrXrJW"
      },
      "outputs": [],
      "source": [
        "print('### 猫画像 ###')\n",
        "print('データ数 x 次元数 = {0[0]} x {0[1]}'.format(cat.shape))\n",
        "\n",
        "# 最初の 20 枚を表示 \n",
        "img = mosaicImage(cat, 5, 4)\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h7GCZliX1T3"
      },
      "source": [
        "(5) クラスタリングを実行して結果を可視化しましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GxKCOLoX7lh"
      },
      "outputs": [],
      "source": [
        "### クラスタリング\n",
        "#\n",
        "X = cat   # 猫画像データを使用\n",
        "K = 2       # クラスタ数\n",
        "nitr = 10   # 繰り返し回数\n",
        "N = X.shape[0]  # 学習データ数\n",
        "\n",
        "print('# 学習回数  コスト  クラスタ毎の所属データ数')\n",
        "\n",
        "# 初期化\n",
        "centroid = initCentroid(X, K)\n",
        "index = np.empty(N, dtype = int)\n",
        "compIndex(X, centroid, index)\n",
        "cost, Nc = compCost(X, centroid, index)\n",
        "print('{0}  {1:.2f}     {2}'.format(0,  cost, Nc))\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "# 学習の繰り返し\n",
        "for i in range(1, nitr+1):  \n",
        "    compCentroid(X, centroid, index)   # セントロイドを求める（資料2/6 step2）\n",
        "    compIndex(X, centroid, index)         # 各データをクラスタへ割り当てる（同 step3）\n",
        "    cost, Nc = compCost(X, centroid, index)\n",
        "    print('{0}  {1:.2f}     {2}'.format(i,  cost, Nc))\n",
        "\n",
        "print('# 経過時間:', datetime.datetime.now() - start)\n",
        "\n",
        "# クラスタ毎のセントロイドと所属データを可視化\n",
        "#     各行が一つのクラスタに対応，左端がセントロイド，右の画像はそのクラスタに所属する画像の一部\n",
        "img = mosaicImage2(cat, centroid, index, 8)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "#cv2.imwrite('{0}_K{1:03d}.png'.format(ID, K), img)  # 表示している画像をファイルに保存\n",
        "plt.show()\n",
        "s = '''\n",
        "クラスタ毎のセントロイドと所属データを可視化\n",
        "　各行が一つのクラスタに対応，左端がセントロイド，右の画像はそのクラスタに所属する画像の一部\n",
        "'''\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lo4pMhTYKvU"
      },
      "source": [
        "**★★★ 結果を観察しよう＆やってみよう★★★**\n",
        "\n",
        "上記では，猫画像を K = 2 の K-means法でクラスタリングする実験を行っています．左端に表示される画像は，K個のクラスタそれぞれに振り分けられたデータの平均です．\n",
        "\n",
        "K をいろいろ変えて（上記セルの4行目の `K = 2` の `2` を変えて）実行し直して，結果を観察しよう．\n",
        "\n",
        "ただし，データ数がそれほど多くないので，Kをあまり大きくすると空のクラスタができたりしてエラーになるかもしれません．また，K-meansクラスタリングの結果は初期値に依存するので，実行するたびに結果が変わります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlfNl6Y-Uxuv"
      },
      "source": [
        "----\n",
        "### ロジスティック回帰やニューラルネットによる手書き数字画像の識別\n",
        "\n",
        "MNIST と呼ばれる手書き数字画像のデータを使って識別の実験をしてみよう．\n",
        "\n",
        "参考:  http://yann.lecun.com/exdb/mnist/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2QkGlRPb46h"
      },
      "source": [
        "#### データの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UazekGU7ZpjS"
      },
      "source": [
        "(1) データの準備その1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StT7aUsJZrzn"
      },
      "outputs": [],
      "source": [
        "# 上記サイトから 4 つのファイルを入手し， gunzip\n",
        "! for fn in train-images-idx3-ubyte t10k-images-idx3-ubyte train-labels-idx1-ubyte t10k-labels-idx1-ubyte; do if [ ! -e ${fn} ]; then wget -nc http://yann.lecun.com/exdb/mnist/${fn}.gz ; gunzip ${fn}.gz; fi; done\n",
        "! ls -l\n",
        "\n",
        "# MNIST のためのクラスの定義\n",
        "\n",
        "import struct\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class MNIST:\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        fnImageL = 'train-images-idx3-ubyte'\n",
        "        fnImageT = 't10k-images-idx3-ubyte'\n",
        "        fnLabelL = 'train-labels-idx1-ubyte'\n",
        "        fnLabelT = 't10k-labels-idx1-ubyte'\n",
        "    \n",
        "        if not os.path.exists(fnImageL) or not os.path.exists(fnImageT) or not os.path.exists(fnLabelL) or not os.path.exists(fnLabelT):\n",
        "            print('Please get the MNIST files first.')\n",
        "            return\n",
        "       \n",
        "        self.fnImage = {'L': fnImageL, 'T': fnImageT}\n",
        "        self.fnLabel  = {'L': fnLabelL, 'T': fnLabelT}\n",
        "        self.nrow = 28\n",
        "        self.ncol = 28\n",
        "        self.nclass = 10\n",
        "        \n",
        "        \n",
        "    def getLabel( self, LT ):\n",
        "        \n",
        "        return _readLabel( self.fnLabel[LT] )\n",
        " \n",
        " \n",
        "    def getImage( self, LT ):\n",
        "        \n",
        "        return _readImage( self.fnImage[LT] )\n",
        " \n",
        " \n",
        "##### reading the label file\n",
        "#\n",
        "def _readLabel( fnLabel ):\n",
        " \n",
        "    f = open( fnLabel, 'rb' )\n",
        " \n",
        "    ### header (two 4B integers, magic number(2049) & number of items)\n",
        "    #\n",
        "    header = f.read( 8 )\n",
        "    mn, num = struct.unpack( '>2i', header )  # MSB first (bigendian)\n",
        "    assert mn == 2049\n",
        "    #print mn, num\n",
        " \n",
        "    ### labels (unsigned byte)\n",
        "    #\n",
        "    label = np.array( struct.unpack( '>%dB' % num, f.read() ), dtype = int )\n",
        " \n",
        "    f.close()\n",
        " \n",
        "    return label\n",
        "\n",
        " \n",
        "##### reading the image file\n",
        "#\n",
        "def _readImage( fnImage ):\n",
        " \n",
        "    f = open( fnImage, 'rb' )\n",
        " \n",
        "    ### header (four 4B integers, magic number(2051), #images, #rows, and #cols\n",
        "    #\n",
        "    header = f.read( 16 )\n",
        "    mn, num, nrow, ncol = struct.unpack( '>4i', header ) # MSB first (bigendian)\n",
        "    assert mn == 2051\n",
        "    #print mn, num, nrow, ncol\n",
        " \n",
        "    ### pixels (unsigned byte)\n",
        "    #\n",
        "    npixel = ncol * nrow\n",
        "    #pixel = np.empty( ( num, npixel ), dtype = int )\n",
        "    #pixel = np.empty( ( num, npixel ), dtype = np.int32 )\n",
        "    pixel = np.empty( ( num, npixel ) )\n",
        "    for i in range( num ):\n",
        "        buf = struct.unpack( '>%dB' % npixel, f.read( npixel ) )\n",
        "        pixel[i, :] = np.asarray( buf )\n",
        " \n",
        "    f.close()\n",
        " \n",
        "    return pixel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-udfSxVag7j"
      },
      "source": [
        "(2) データの準備その2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP93nnIoak00"
      },
      "outputs": [],
      "source": [
        "# MNIST の学習データ\n",
        "mn = MNIST()\n",
        "datL = mn.getImage('L')\n",
        "labL = mn.getLabel('L')\n",
        "NL = datL.shape[0]\n",
        "print('# 学習データのデータ数: ', NL)\n",
        "D = mn.nrow * mn.ncol\n",
        "K = 10\n",
        "\n",
        "# 学習データの最初の50個を可視化してみる\n",
        "img = mosaicImage(datL[:50, :], 10, 5, nrow=28, ncol=28)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "\n",
        "# これらの正解ラベル\n",
        "for i in range(5):\n",
        "    print(labL[i*10:((i+1)*10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNesQEN9bP-T"
      },
      "source": [
        "このデータセットでは，1つの手書き数字画像は 28 x 28 画素ありますので，1つのデータを $784 (=28\\times 28)$ 次元ベクトルとして扱うことになります．\n",
        "画像の上に並んだ数字 `5 0 4 1 9 ...` は，これらの画像の手書き数字に対応する実際の数（正解）を表しています．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0DMgSrtcDbu"
      },
      "source": [
        "#### ロジスティック回帰とニューラルネットによる識別\n",
        "\n",
        "前回ちょこっと説明した「ロジスティック回帰」は，与えられたデータを2通りに分類するものでしたが，よりたくさんの分類ができるように拡張できます．ここでは，784次元ベクトル6万個から成る手書き数字画像データを，0 から 9 の10通りに分類させてみましょう．\n",
        "\n",
        "また，最近のいわゆる人工知能では，「ニューラルネット」という機械学習の仕組みがよく使われます（「深層学習 (deep learning)」ともいいます）．\n",
        "以下では，簡単なニューラルネットの例でも実験できるようにしてあります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdD8AqG0dL4p"
      },
      "source": [
        "(3) ネットワークモデルと学習アルゴリズムを定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHnkB1vMdXFw"
      },
      "outputs": [],
      "source": [
        "### ネットワークを定義する関数\n",
        "#\n",
        "def makeNetwork(model_type, D, K, H1 = 256, H2 = 128):\n",
        "    \n",
        "    network = keras.models.Sequential()\n",
        "    \n",
        "    if model_type == 1:  # ロジスティック回帰\n",
        "        print(f'# ロジスティック回帰やで．入力は{D}次元，出力は{K}次元ですわ．')\n",
        "        network.add(keras.layers.Dense(K, input_shape = (D,)))\n",
        "        network.add(keras.layers.Activation('softmax'))\n",
        "    elif model_type == 2:  #  2層 MLP\n",
        "        print(f'# 2層MLPでおま．入力は{D}次元，隠れ層のニューロン数は {H1}，出力のニューロン数は {K} でっせ．')\n",
        "        network.add(keras.layers.Dense(H1, input_shape = (D,)))\n",
        "        network.add(keras.layers.Activation('relu'))\n",
        "        network.add(keras.layers.Dense(K))\n",
        "        network.add(keras.layers.Activation('softmax'))\n",
        "    elif model_type == 3:  #  3層 MLP\n",
        "        print(f'# 3層MLPでおま．入力は{D}次元，ニューロン数は，(1つ目の隠れ層) - (2つ目の隠れ層) - (出力) の順に {H1} - {H2} - {K} でんがなまんがな．')\n",
        "        network.add(keras.layers.Dense(H1, input_shape = (D,)))\n",
        "        network.add(keras.layers.Activation('relu'))\n",
        "        network.add(keras.layers.Dense(H2))\n",
        "        network.add(keras.layers.Activation('relu'))\n",
        "        network.add(keras.layers.Dense(K))\n",
        "        network.add(keras.layers.Activation('softmax'))\n",
        "    else:\n",
        "        exit('makeNetwork: model_type error')\n",
        "\n",
        "    # パラメータ最適化法の設定．確率的勾配降下法(Stochastic Gradient Descent)を用いる\n",
        "    #optimizer = keras.optimizers.SGD(lr = 0.1, momentum = 0.9)\n",
        "    optimizer = keras.optimizers.SGD(learning_rate = 0.1, momentum = 0.9)\n",
        "\n",
        "    network.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OfKLBt8dcU0"
      },
      "source": [
        "(4) 学習を実行し，テストデータ（学習に使っていない未知のデータ）で検証します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNWlpkgNdlP9"
      },
      "outputs": [],
      "source": [
        "### ネットワークの作成\n",
        "#\n",
        "network = makeNetwork(1, D, K)  # 第1引数が 1 だとロジスティック回帰， 2 だと2層MLP， 3 だと3層MLP\n",
        "\n",
        "### 学習\n",
        "#\n",
        "batchsize = 128\n",
        "XL = datL / 255\n",
        "YL = keras.utils.to_categorical(labL, num_classes = K)\n",
        "\n",
        "print('# 学習回数  コスト  誤識別率[%]')\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "for i in range(10000+1):  # 学習の繰り返し\n",
        "\n",
        "    if (i < 500 and i % 100 == 0) or (i % 500 == 0):\n",
        "        lossL, accL = network.evaluate(XL, YL, batch_size = batchsize, verbose = 0)  # 評価\n",
        "        print('{}          {:.3f}          {:.2f}'.format(i, lossL, (1-accL)*100))\n",
        "    \n",
        "    ii = np.random.randint(XL.shape[0], size = batchsize)\n",
        "    network.train_on_batch(XL[ii], YL[ii])     # 学習\n",
        "\n",
        "print('# 経過時間:', datetime.datetime.now() - start)\n",
        "\n",
        "lossL, accL = network.evaluate(XL, YL, batch_size = batchsize, verbose = 0)\n",
        "print('# 学習データに対するコストと誤識別率[%]: {:.3f}   {:.2f}'.format(lossL, (1-accL)*100))\n",
        "\n",
        "### テストデータの準備\n",
        "#\n",
        "datT = mn.getImage('T')\n",
        "labT = mn.getLabel('T')\n",
        "NT = datT.shape[0]\n",
        "print('# テストデータのデータ数: ', NT)\n",
        "\n",
        "### テスト\n",
        "#\n",
        "XT = datT / 255\n",
        "YT = keras.utils.to_categorical(labT, num_classes = K)\n",
        "lossT, accT = network.evaluate(XT, YT, batch_size = batchsize, verbose = 0)\n",
        "print('# テストデータに対するコストと誤識別率[%]: {:.3f}   {:.2f}'.format(lossT, (1-accT)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KfdZ07KeqQi"
      },
      "source": [
        "**★★★ 結果を観察しよう＆やってみよう★★★**\n",
        "\n",
        "上記の「誤識別率」というのは，与えられたデータのうち，識別を間違えた（正解と違う数字と判定した）画像の割合です．「学習データ」は学習に使ったデータ，「テストデータ」は学習時に見たことのない未知のデータです．ロジスティック回帰だと，テストデータの8%くらいは間違えます．\n",
        "\n",
        "上記のセルの3行目の\n",
        "```\n",
        "network = makeNetwork(1, D, K)  # 第1引数が 1 だとロジスティック回帰， 2 だと2層MLP， 3 だと3層MLP\n",
        "```\n",
        "というところを，コメントにしたがって書き換えると，ニューラルネットを使った実験もできます．実行して，結果がどう変わるか見てみましょう．ニューラルネットの学習は，ロジスティック回帰より時間がかかります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivsIJzEPhR-3"
      },
      "source": [
        "----\n",
        "### 1000種類の画像を認識するニューラルネットを動かしてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59sBT7-8hk3V"
      },
      "source": [
        "(1) 画像の入手"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsDMgChlhRY9"
      },
      "outputs": [],
      "source": [
        "# 自分で画像をアップロードして識別させてみる場合は，以下を False に\n",
        "useUni3 = True\n",
        "\n",
        "if useUni3:\n",
        "    # うに様の画像を入手\n",
        "    ! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/PIP/uni3.png\n",
        "else:\n",
        "    # テストに使う画像をアップロード\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TbCp79ehwEH"
      },
      "source": [
        "上記が正しく実行できれば，最後の行に\n",
        "```\n",
        "-rw-r--r-- 1 root root   227576 May  3  2018 uni3.png\n",
        "```\n",
        "のように，`uni3.png` というファイル名があるはずです．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCknVIoOh-7A"
      },
      "source": [
        "(2) 画像を表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKgab9-QiEFD"
      },
      "outputs": [],
      "source": [
        "# 画像のファイル名を指定\n",
        "if useUni3:\n",
        "    fn = 'uni3.png'\n",
        "else:\n",
        "    fn = 'hoge.jpg'   ### 自分でアップロードした画像を使う場合は，ここを修正\n",
        "\n",
        "# 入手した画像を読み込む\n",
        "imgRaw = cv2.imread(fn)\n",
        "\n",
        "# 画像を表示\n",
        "displayImage(imgRaw)\n",
        "print(imgRaw.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz_e4h9piDpX"
      },
      "source": [
        "(3) 学習済みのニューラルネットのパラメータを入手"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcJvImJbiaXI"
      },
      "outputs": [],
      "source": [
        "# VGG16 ネットワークモデルを作成\n",
        "#   はじめて実行する時は，ネットワークパラメータをダウンロードするのに少し時間がかかる\n",
        "model = VGG16(weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUFxQDJfilSM"
      },
      "source": [
        "(4) ニューラルネットに識別させる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iDvs7z1io7L"
      },
      "outputs": [],
      "source": [
        "# 画像を読み込み．入力は 224x224 に大きさを調整される\n",
        "img = image.load_img(fn, target_size = (224, 224))\n",
        "\n",
        "# 前処理\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "# ネットワークの出力を求める\n",
        "preds = model.predict(x)\n",
        "\n",
        "# 画像を表示\n",
        "plt.axis('off')\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# 5位までの結果を表示（softmax出力の値 = 確率が高い方5つ）\n",
        "print()\n",
        "out = decode_predictions(preds, top=5)[0]\n",
        "for i, item in enumerate(out):\n",
        "    print('{1}位 {0[0]}  {0[1]}  {0[2]:.5f}'.format(item, i+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tLoh67tiy91"
      },
      "source": [
        "**★★★ 結果を観察しよう ★★★**\n",
        "\n",
        "この実験で用いているニューラルネットは，120万枚の画像を学習データとして，1000種類の物体・画像を識別するよう学習したものです．この学習の過程は，高性能なPCでも1週間くらいかかるので，ここではすでに学習済みのニューラルネットを利用しています．\n",
        "\n",
        "この設定では，「ネコ」は一つのクラスではなく，複数に分かれてます．\n",
        "\n",
        "weasel 等の日本語訳は以下をどぞ．上記の右端の値は，ニューラルネットの出力そのものです．入力画像がそのクラスのものである確率の推定値になってます．そのクラスであることの確信度，とも言えます．\n",
        "\n",
        "```\n",
        "weasel: イタチ\n",
        "lynx: ヤマネコ\n",
        "black-footed_ferret: クロアシイタチ\n",
        "Egyptian_cat: エジプト産のネコ，エジプシャンマウ(?)\n",
        "polecat: スカンク(?)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h2WyAYajaxG"
      },
      "source": [
        "**★★★ やってみよう ★★★**\n",
        "\n",
        "次のようにすると，自分で用意した画像を識別させてみることができます．\n",
        "やってみよう．\n",
        "\n",
        "1. 画像を入手．ファイル名が長かったり日本語が含まれてたりするとうまく扱えないことがあるので，簡単な名前に変更しておくとよい．\n",
        "1. 「(1) 画像を入手」の以下の行（2行目）の `True` を `False` に書き換えてセルを実行し直す．\n",
        "```\n",
        "useUni3 = True\n",
        "```\n",
        "1. 画像をアップロードする．\n",
        "1. 「(2) 画像を表示」の以下の行（5行目）の `hoge.png` を，自分がアップロードしたファイルの名前に変更する．\n",
        "```\n",
        "    fn = 'hoge.png'   ### 自分でアップロードした画像を使う場合は，ここを修正\n",
        "```\n",
        "1. 画像が表示されることを確認．\n",
        "1. 「(4) ニューラルネットに識別させる」を実行\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9o3NJDZkSev"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO96KihGT7O5AEdxgR3Bz6q",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ex01noteA.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

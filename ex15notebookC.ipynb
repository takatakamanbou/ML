{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2023/ex15notebookC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex15notecookC\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2023)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# 「1000種類の物体を識別するニューラルネットを動かしてみよう」のためのほげ\n",
        "import pickle\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import json"
      ],
      "metadata": {
        "id": "Uba-rqwa906l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 手書き数字識別の例\n",
        "---\n",
        "\n",
        "授業で学んだことを実際のデータで理解するための例です．"
      ],
      "metadata": {
        "id": "CF8lmoTU83pN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備\n",
        "\n"
      ],
      "metadata": {
        "id": "1T4uqbjS9mw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これまでに何回も登場したものと同様の，28x28画素の手書き数字のデータです．"
      ],
      "metadata": {
        "id": "6fQ288EF-B2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 手書き数字データの入手\n",
        "\n",
        "# 一つ目のデータセット\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/minimnist.npz\n",
        "rv = np.load('minimnist.npz')\n",
        "datL = rv['datL'].astype(float)[:2500, :]\n",
        "labL = rv['labL'][:2500]\n",
        "datT = rv['datT'].astype(float)[:2500, :]\n",
        "labT = rv['labT'][:2500]\n",
        "print(datL.shape, labL.shape, datT.shape, labT.shape)\n",
        "\n",
        "# 二つ目のデータセット\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/minimnist_biased.npz\n",
        "rv = np.load('minimnist_biased.npz')\n",
        "datLb = rv['datL'].astype(float)\n",
        "labLb = rv['labL']\n",
        "datTb = rv['datT'].astype(float)\n",
        "labTb = rv['labT']\n",
        "print(datLb.shape, labLb.shape, datTb.shape, labTb.shape)\n",
        "\n",
        "K = 10 # クラス数\n",
        "D = datL.shape[1] # データの次元数 28 x 28 = 784"
      ],
      "metadata": {
        "id": "HT3F9gLm84yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを画像として表示するための関数\n",
        "#\n",
        "def display(data, nx, ny, nrow=28, ncol=28, gap=4):\n",
        "\n",
        "    assert data.shape[1] == nrow*ncol\n",
        "\n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype = int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        for ix in range(nx):\n",
        "            if iy*nx+ix < data.shape[0]:\n",
        "                ltx = ix*(ncol + gap) + gap\n",
        "                img[lty:lty+nrow, ltx:ltx+ncol] = data[iy*nx+ix].reshape((nrow, ncol))\n",
        "\n",
        "    # 画像の出力\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VJDeSJmO9v7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 一つ目のデータセットで識別実験\n",
        "\n",
        "一つ目のデータセットに最近傍法を適用し，テストデータを識別させてみましょう．"
      ],
      "metadata": {
        "id": "ye1WQuV6CPvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習データはこんなんです．"
      ],
      "metadata": {
        "id": "a95YzKArCdG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx, ny = 10, 5\n",
        "display(datL[:50], nx, ny)"
      ],
      "metadata": {
        "id": "iLw0s0Or-JEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iy in range(ny):\n",
        "    print(labL[iy*nx:(iy+1)*nx])"
      ],
      "metadata": {
        "id": "11HkhHSO-UCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "クラスごとに正解率を出してみると...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lV_6TjXt-esg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測されたクラス番号を格納する配列\n",
        "predT = np.empty_like(labT)\n",
        "NT, D = datT.shape\n",
        "\n",
        "# 最近傍法で識別\n",
        "for n in range(NT):\n",
        "    d2 = np.sum((datT[n, :] - datL)**2, axis=1)\n",
        "    predT[n] = labL[np.argmin(d2)]\n",
        "\n",
        "# クラスごとの正解率を算出\n",
        "nca = 0\n",
        "for ic in range(K):\n",
        "    idx = labT == ic\n",
        "    nc = np.sum(predT[idx] == ic)\n",
        "    nn = np.sum(idx)\n",
        "    print(f'class{ic}: {nc}/{nn}')\n",
        "    nca += nc\n",
        "\n",
        "print(f'total: {nca}/{NT}')"
      ],
      "metadata": {
        "id": "YoN0vu7w-YDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんなん出ました．"
      ],
      "metadata": {
        "id": "pfdNG5uRCBLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 二つ目のデータセットで識別実験\n",
        "\n",
        "二つ目のデータセットに最近傍法を適用し，テストデータを識別させてみましょう．\n",
        "二つのデータセットは，学習データのみ異なり，テストデータは全く同じものです．"
      ],
      "metadata": {
        "id": "JgSyL9pdCoxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習データはこんなんです．\n",
        "一つ目と同じようなものに見えます．データ数も同じです．"
      ],
      "metadata": {
        "id": "O-ZNZW1_C0Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx, ny = 10, 5\n",
        "display(datLb[:50], nx, ny)"
      ],
      "metadata": {
        "id": "hoG8GteBCuJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iy in range(ny):\n",
        "    print(labLb[iy*nx:(iy+1)*nx])"
      ],
      "metadata": {
        "id": "9PCkr0gfCyX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "しかし，識別させてみると，次のような結果になります．"
      ],
      "metadata": {
        "id": "lUf1l4BwDQ-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測されたクラス番号を格納する配列\n",
        "predTb = np.empty_like(labT)\n",
        "NT, D = datT.shape\n",
        "\n",
        "# 最近傍法で識別\n",
        "for n in range(NT):\n",
        "    d2 = np.sum((datT[n, :] - datLb)**2, axis=1)\n",
        "    predTb[n] = labLb[np.argmin(d2)]\n",
        "\n",
        "# クラスごとの正解率を算出\n",
        "nca = 0\n",
        "for ic in range(K):\n",
        "    idx = labT == ic\n",
        "    nc = np.sum(predTb[idx] == ic)\n",
        "    nn = np.sum(idx)\n",
        "    print(f'class{ic}: {nc}/{nn}')\n",
        "    nca += nc\n",
        "\n",
        "print(f'total: {nca}/{NT}')"
      ],
      "metadata": {
        "id": "L3XEA7nvDZR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "全体の正解率が下がっていますが，特に class2 と class9 の精度が低いようです．\n",
        "正解率の低いクラスでどんな間違い方をしているか，詳しく見てみましょう．"
      ],
      "metadata": {
        "id": "mwK91R40_WM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解が class2 であるテストデータのうち，予測を間違えたもの\n",
        "idx = (labT == 2) & (predTb != 2)\n",
        "XX = datTb[idx, :]\n",
        "YY = predTb[idx]\n",
        "nx, ny = 10, 4\n",
        "display(XX[:nx*ny], nx, ny)\n",
        "for iy in range(ny):\n",
        "    print(YY[iy*nx:(iy+1)*nx])"
      ],
      "metadata": {
        "id": "Vup6CdD9_OTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記は，正解が class2 であるテストデータのうち，予測を間違えたものをすべて並べてあります．\n",
        "そりゃ間違えても仕方ないな，という例もありますが，普通に読めるきれいな「2」もたくさん間違えているようです．"
      ],
      "metadata": {
        "id": "Mkw8VzMC_7xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解が class9 であるテストデータのうち，予測を間違えたもの\n",
        "idx = (labT == 9) & (predTb != 9)\n",
        "XX = datTb[idx, :]\n",
        "YY = predTb[idx]\n",
        "nx, ny = 10, 4\n",
        "display(XX[:nx*ny], nx, ny)\n",
        "for iy in range(ny):\n",
        "    print(YY[iy*nx:(iy+1)*nx])"
      ],
      "metadata": {
        "id": "qOQaJJg5_1Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "同様に，正解が class9 であるテストデータのうち，予測を間違えたものは上記の通りです．\n",
        "やはり，まともそうな「9」をたくさん間違えているようです．"
      ],
      "metadata": {
        "id": "qXtP0xYMAdcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 学習データを眺めて考えてみよう"
      ],
      "metadata": {
        "id": "mW-soqlFE3sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "どうして上記のような実験結果となるのか，学習データを眺めて理由を考えましょう．"
      ],
      "metadata": {
        "id": "gsTcy_AeGKb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 一つ目のデータセット\n",
        "idx = labL == 2\n",
        "XX = datL[idx, :]\n",
        "nx, ny = 16, 10\n",
        "display(XX[:nx*ny], nx, ny)"
      ],
      "metadata": {
        "id": "lbV8qpMQAZkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 二つ目のデータセット\n",
        "idx = labLb == 2\n",
        "XX = datLb[idx, :]\n",
        "nx, ny = 16, 10\n",
        "display(XX[:nx*ny], nx, ny)"
      ],
      "metadata": {
        "id": "PVc-lNavFqyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 一つ目のデータセット\n",
        "idx = labL == 9\n",
        "XX = datL[idx, :]\n",
        "nx, ny = 16, 10\n",
        "display(XX[:nx*ny], nx, ny)"
      ],
      "metadata": {
        "id": "4b1LKaFNF3nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 二つ目のデータセット\n",
        "idx = labLb == 9\n",
        "XX = datLb[idx, :]\n",
        "nx, ny = 16, 10\n",
        "display(XX[:nx*ny], nx, ny)"
      ],
      "metadata": {
        "id": "Jm1rFzloGw06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "二つ目のデータセットでの識別実験で間違えてるのはどんな画像だったかを見返しながら上の二つの画像を比較するとよいでしょう．答えを知りたければ，takataka に尋ねてください．ヒント: これらは，「機械学習と公平性」の話と関係しています．"
      ],
      "metadata": {
        "id": "runU0sTJGX1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1000種類の物体を識別するニューラルネットを動かしてみよう\n",
        "---\n",
        "\n",
        "ニューラルネットを用いた画像識別の実験をやってみましょう． いろんなものが識別できた方が楽しいと思いますので，1000種類の物体を識別させてみます． ただし，そういうことができるニューラルネットワークを一から学習させようとすると大変ですので，ここではすでに学習済みのものを利用することにします．"
      ],
      "metadata": {
        "id": "hOfsc2j5qa1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "m_05KKmfwFQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは実験に使う画像データを準備します．\n",
        "\n",
        "**注意: 以下の画像をこの実験以外の目的で使用してはいけません**"
      ],
      "metadata": {
        "id": "P-AmCU9NCRGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/adversarialphoto.pickle\n",
        "with open('adversarialphoto.pickle', 'rb') as f:\n",
        "    hoge = pickle.load(f)\n",
        "\n",
        "imgList = []\n",
        "for i, d in enumerate(hoge):\n",
        "    img = Image.frombytes(**d)\n",
        "    imgList.append(img)\n",
        "    if i >= 4:\n",
        "        continue\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Io3_Xdj5NMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000個あるカテゴリの番号とそのラベルの対応表を作成します．"
      ],
      "metadata": {
        "id": "dwjnxlnZqkSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageNet カテゴリラベルを表すJSONファイルを入手\n",
        "!wget -nc https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
        "class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
        "\n",
        "K = len(class_index)\n",
        "labels = {}\n",
        "for ik, key in enumerate(class_index.keys()):\n",
        "    labels[ik] = f'{class_index[key][0]} {class_index[key][1]}'\n",
        "    if 276 <= ik < 300:\n",
        "        print(ik, labels[ik])"
      ],
      "metadata": {
        "id": "-5nFrG_ywpOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の出力は，1000カテゴリのうちの一部のものの名前を表します．「ネコ」みたいなものも1カテゴリではなく，281番 'tabby'（ぶち柄の猫），282番 'tiger_cat'（トラ縞の猫）等々のように分かれています．"
      ],
      "metadata": {
        "id": "goVX8Ln9CZ-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習済みのニューラルネットワークのパラメータを入手します．\n",
        "規模の大きいネットワークでパラメータがたくさんありますので，読み込みに少し時間がかかります．"
      ],
      "metadata": {
        "id": "v0srx3ogtOaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "vgg16.eval()\n",
        "print(vgg16)"
      ],
      "metadata": {
        "id": "uLg8zK7HyDKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルを実行すると，次のことが行われます．\n",
        "1. ニューラルネットの学習モデルを作成する．\n",
        "1. 学習済みのネットワークパラメータの値を読み込んでこのネットワークのパラメータに設定する．\n",
        "1. ネットワークモデルの構造を表示する．"
      ],
      "metadata": {
        "id": "g-V8tZ5Atyqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考:\n",
        "\n",
        "ここで用いているのは VGG16 というニューラルネットモデルです．イギリスオックスフォード大学の [Visual Geometry Group(VGG)](https://www.robots.ox.ac.uk/~vgg/) という研究グループが作った VGG-net というニューラルネットモデルのうちの，層が16層あるものです．\n",
        "VGG-net は，2014年に行われた [ILSVRC2014](https://www.image-net.org/challenges/LSVRC/2014/) という画像識別のコンペティションで世界第2位となったニューラルネットモデルです．\n",
        "ILSVRC2014では，[ImageNet](https://www.image-net.org/) という大規模な画像データセットの中から選ばれた 1000 種類の物体の画像約120万枚を学習データとしていました．\n"
      ],
      "metadata": {
        "id": "103RZrZeu1vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "画像をネットワークに入力できる形式に加工する処理を定義しておきます．\n"
      ],
      "metadata": {
        "id": "TVwByjcG1cyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "GeUATyKI2AYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験その1\n",
        "\n",
        "上記のサンプル画像たちを VGG16 に識別させてみましょう．\n"
      ],
      "metadata": {
        "id": "uyWss1-izFXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 以下で 0 から 3 までの整数を選ぶと4つのサンプル画像の中から一つを選ぶことができます．\n",
        "i = 0 #@param [0, 1, 2, 3] {type: 'raw'}\n",
        "img = imgList[i]\n",
        "\n",
        "# 画像を表示\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(imgList[i]), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "9pp3WWir8sLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の画像の下の出力は，1000個のカテゴリの中で，ネットワークの出力の値が大きかったもの上位5位までの，出力の値とカテゴリラベルを表します．\n",
        "出力の値は，そのカテゴリと判定することの「確信度」と解釈できます．"
      ],
      "metadata": {
        "id": "-dKliElj-rnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験その2\n",
        "\n",
        "上記のサンプル画像は4枚ありましたが，実は他にまだ4枚あります．\n",
        "次のセルで `i` を 4 から 7 まで選ぶと画像とニューラルネットの出力を確認できます．"
      ],
      "metadata": {
        "id": "wHmVkTJEJJxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 以下で 0 から 7 までの整数を選ぶと8つのサンプル画像の中から一つを選ぶことができます．\n",
        "i = 4 #@param [0, 1, 2, 3, 4, 5, 6, 7] {type: 'raw'}\n",
        "img = imgList[i]\n",
        "\n",
        "# 画像を表示\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(imgList[i]), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "3E5s0A-UJk4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`i` を 4 から 7 にしたときの画像は，「再現性・ロバスト性」の話の中に登場した「敵対的事例」のサンプルです．VGG16モデルが，0番から999番まであるクラスのうち999番の"
      ],
      "metadata": {
        "id": "AXCitRROJ8LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels[999]"
      ],
      "metadata": {
        "id": "FKOTd8QoKO4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "と誤識別しやすくなる方向に画像を少し歪ませたものです．その結果どんなクラスと間違えているか，出力を確認してみてください．"
      ],
      "metadata": {
        "id": "zB094n5IKbB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "［補足］\n",
        "- ここで用いている画像例は，元画像がかなり高い確信度で正しいクラスに識別されている例ばかりです．そのため，誤識別させるためにかなり大きく歪ませており，目で見て分かるほどになってしまっています．\n",
        "実際には，人間には気づかないほどの小さな歪を画像に混入させるだけで識別結果を捻じ曲げられる場合もあります．\n",
        "- ここでは，Fast Gradient Sign Method と呼ばれる手法で敵対的事例を作っています．参考: https://pytorch.org/tutorials/beginner/fgsm_tutorial.html"
      ],
      "metadata": {
        "id": "GkBEaRIYKMMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験その3\n",
        "\n",
        "自分で用意した画像でも実験してみましょう．\n",
        "\n",
        "- 上記では動物の例ばかりですが，1000のカテゴリの中にはそれ以外にも様々なものがあります（「人間」というカテゴリはありません．どうなる？）\n",
        "- 面白い／不思議な結果が得られたら takataka に見せてくれると喜びます\n",
        "\n"
      ],
      "metadata": {
        "id": "Ss4c8IAe_9Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) まずは，ウェブ等で適当な画像を探して，自分のコンピュータへ保存しましょう．ファイル名が長かったり日本語を含んでいる場合は，短い名前に変更しておくのがよいです．\n",
        "\n",
        "(2) 以下のセルを実行して，ファイルをアップロードします．"
      ],
      "metadata": {
        "id": "Sii3vXZ8AU2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab へファイルをアップロード\n",
        "try:\n",
        "    from google.colab import files\n",
        "    rv = files.upload()\n",
        "except:\n",
        "    print('このコードは Colab 以外の環境では実行できないよ．')"
      ],
      "metadata": {
        "id": "o83_b8kY9_Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 以下のセルの1行目のファイル名を上記でアップロードしたものに変えて実行しましょう．アルファベット大文字小文字の区別もありますので注意．うまくいけば画像が表示されるはずです．"
      ],
      "metadata": {
        "id": "PHZCqDSHBiG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ↓のファイル名をアップロードしたものに変更してね\n",
        "myimg = Image.open('hoge.png')\n",
        "if myimg.mode != 'RGB':\n",
        "    myimg = myimg.convert('RGB')\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(myimg)\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F72S_3eO9Ask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) 以下のセルを実行すれば結果が表示されます．"
      ],
      "metadata": {
        "id": "YGckmXO7Bzs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(myimg), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "u8vrSrciBbgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e94_duuoCEcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
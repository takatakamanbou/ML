{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/2023/ex10notebookB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex10notebookB\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2023)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## 過適合の抑制とモデル選択(2)\n",
        "----\n",
        "\n",
        "「過適合の抑制とモデル選択(1)」に続いて，過適合を抑制して汎化能力の高い学習モデルを得る方法について説明します．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 検証データを用いたモデルやハイパーパラメータの選択\n",
        "\n"
      ],
      "metadata": {
        "id": "m_05KKmfwFQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### モデル・ハイパーパラメータの選択\n",
        "\n",
        "機械学習においては，一つの問題に対して複数の学習手法や学習モデルを用いることがよくあります．同じ手法・モデルでも，ハイパーパラメータを変えて学習を繰り返す場合もあります．\n",
        "そのような場合，複数用意した手法・モデル・ハイパーパラメータのそれぞれで学習の結果が得られますので，それらの中から良いものを選びたくなります．選ぶ基準にもいろいろ考えられますが，最も重要なのは汎化性能でしょう．\n",
        "ここでは，複数の手法・モデル・ハイパーパラメータの中から，汎化性能が高いものを選択する方法について説明します．\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "an3sdfWidVAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下，「過適合の抑制とモデル選択(1)」の例題をもう一度用いて説明をします．\n",
        "この例題は，最小二乗法によって学習データに$D$次の多項式を当てはめるというものでした．$D$の値をいろいろ変えて学習させた後に，学習データと，それとは別に用意した検証データに対する平均二乗誤差を計算すると，以下のようになっていました．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/modelselection.png\" width=\"50%\">\n",
        "\n",
        "横軸が $D$ で，縦軸が平均二乗誤差の大きさです．赤い点は学習データに対する誤差，青い点は検証データに対する誤差を表しています．この場合，学習データに対する誤差は $D$ が大きい方がおおむね小さくなっていますが，検証データに対する誤差は $D=6$で最小となっていました． "
      ],
      "metadata": {
        "id": "jnalJ_8xcqB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この結果から，この例題に多項式当てはめの最小二乗法を適用する場合，多項式の次数 $D$ を 1 以上 20 以下の範囲で選ぶならば，$D=6$ が最も適切であると結論付けることができます．\n",
        "過適合の可能性があるため，学習データに対する誤差は汎化性能の指標として適当ではありません．一方，検証データは学習には用いていないため，学習モデルにとっては未知のデータです．そのため，検証データに対する誤差は，汎化性能の指標とすることができます．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WBzimUd1djdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "別の例として，階層型ニューラルネットワークを用いて何らかのデータの識別を行っている場合を考えてみましょう．\n",
        "用いたニューラルネットは，下図左のように中間層が一つだけのものとします．中間層のニューロン数を $200, 300, 500, 1000, 2000$ とした5つの学習モデルを用意して，それぞれ同じ学習データで学習させた後に，検証データを用いて識別率を計算してみると，下図右のようになったとしましょう．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/modelselection3.png\" width=\"50%\">\n",
        "\n",
        "この場合，先の例と同様に，検証データに対する識別率をこれらの学習モデルの汎化性能の指標と考えて，中間層ニューロン数$1000$のモデルを選べばよいでしょう．\n",
        "\n",
        "ここでは中間層が1層のものだけでしたが，中間層が2層や3層のものも含めて様々な構成の学習モデルを作って，それらの中からどれかを選ぶということも同じようにできますね．\n"
      ],
      "metadata": {
        "id": "PC3h3ONIDGZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の二つはいずれも，学習モデルのパラメータ数に直接関係するようなところの選択の話でした．\n",
        "次は少し違う例として，ハイパーパラメータを選択する場合を取り上げます．\n",
        "\n",
        "「パラメータの正則化」で説明した正則化の方法では，正則化項の効き目をコントロールする $\\alpha$ というハイパーパラメータが登場しました．\n",
        "その値は学習によって自動で決まるものではありませんが，多項式モデルの次数やニューラルネットワークのニューロン数などと同様に，検証データを用いて決めてやることができます．"
      ],
      "metadata": {
        "id": "Z0CyvA0Uowuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次の図は，「過適合の抑制とモデル選択(1)」の例題で，$D=20$ に固定して，正則化項の重み $\\alpha$ の値を様々に変えたときの，学習データおよび検証データに対する平均二乗誤差のグラフです．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/modelselection2.png\" width=\"50%\">\n",
        "\n",
        "グラフの横軸が $\\alpha$ の値，縦軸が平均二乗誤差の大きさを表します．この図を見ると，ここに示した $\\alpha$ の範囲では，$\\alpha = 0.0002$ のときに検証データに対する誤差が最小となっていることが分かります．したがって，この $\\alpha$ の値を採用するのが適切でしょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "hktWiXdAqSkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これまでこの授業で取り上げてきたハイパーパラメータには，$k$-近傍法の$k$，決定木の最大の深さ等々，様々なものがありますが，同様に検証データを用いて決めてやることが可能です．\n",
        "また，上記の多項式の例で $D$ と $\\alpha$ を同時に変えてその中から最適な組み合わせを探す，といったことももちろん可能です．"
      ],
      "metadata": {
        "id": "sw7bRrN1skZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 検証データはどうやって用意する？"
      ],
      "metadata": {
        "id": "YTsCsdqqsBQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のように，汎化性能を指標として手法・モデル・ハイパーパラメータを選択する場合，学習データとは別に用意した検証データが必要です．\n",
        "検証データを用意する際には，次のようなことを考慮する必要があります．\n",
        "\n",
        "- 検証データは学習データとは異なるデータであること．言わずもがなですが，汎化性能を測るためには，学習データとは異なるデータを用いないといけません．\n",
        "- 検証データ・学習データそれぞれの分布が大きく違っていないこと．学習データと検証データで分布が違う，つまり，性質や値の傾向に違いがあると正確に検証できません．極端な例ですが，カラー画像の識別を学習させているときに，グレイスケール画像（いわゆる白黒画像）で検証するのはNGですね．"
      ],
      "metadata": {
        "id": "iTETLcabtum2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "あらかじめ検証データが用意されているような問題ならばよいですが，実際の問題では，学習データしか用意されていないことが多くあります．\n",
        "そのような場合，「学習データの一部を検証用に分けて，学習に使わないでおく」ことで，検証データを作ってやることができます．\n",
        "しかし，学習データがあまり多くない場合，単に学習用と検証用に分けるだけでは，学習データの数が少なすぎて学習がうまくいかない心配があります．一方，検証データの数が少ないと，正確な検証ができないかもという心配が生じます．\n",
        "\n",
        "そのような場合，学習データを複数のグループに分割して，一部を学習に使い，残りを検証用にするということを，グループを入れ替えながら繰り返す，**交差検証**（cross-validation）という方法をとることがあります．以下では，交差検証の方法の一つである，**$n$-分割交差検証**($n$-fold cross-validation)について説明します．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8As34DBNvt_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$n$-分割交差検証では，学習データを $n$ 個のグループに分けて，$n-1$ 個のグループのデータを学習用に，残り1個を検証用にします．\n",
        "このようにすると，学習用と検証用のデータの分け方が$n$通りできるので，それぞれで学習と検証を行って検証データに対する結果（誤差や識別率など）を$n$個得ます．そして，その平均を指標とします．\n",
        "\n",
        "例えば，$n=4$ として，学習データが A, B, C, D の4グループに分けられる場合，次のように4回の学習・検証を行います．\n",
        "\n",
        "1. A, B, C で学習，D で検証\n",
        "1. A, B, D で学習，C で検証\n",
        "1. A, C, D で学習，B で検証\n",
        "1. B, C, D で学習，A で検証\n",
        "\n",
        "このようにすることで，学習データの数が十分でない場合でもうまく検証することができます．"
      ],
      "metadata": {
        "id": "XebAx_ZMzIpz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Mbh3JKltPvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
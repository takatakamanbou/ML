{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/ML/blob/main/ex06noteC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# ML ex06noteC\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/ML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?ML/2022)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glgWbdlh34P"
      },
      "source": [
        "----\n",
        "## 準備\n",
        "----\n",
        "\n",
        "Google Colab の Notebook では， Python というプログラミング言語のコードを動かして計算したりグラフを描いたりできます．\n",
        "Python は，機械学習・人工知能やデータサイエンスの分野ではメジャーなプログラミング言語ですが，それを学ぶことはこの授業の守備範囲ではありません．以下の所々に現れるプログラムっぽい記述の内容は，理解できなくて構いません．\n",
        "\n",
        "以下，コードセルを上から順に実行してながら読んでいってね．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "import pickle\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WXvQDHGjLD8"
      },
      "source": [
        "----\n",
        "## 1000種類の物体を識別するニューラルネットを動かしてみよう\n",
        "----\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ニューラルネットワークを用いた画像識別の実験をやってみましょう．\n",
        "いろんなものが識別できた方が楽しいと思いますので，1000種類の物体を識別させてみます．\n",
        "ただし，そういうことができるニューラルネットワークを一から学習させようとすると大変ですので，ここではすでに学習済みのものを利用することにします．"
      ],
      "metadata": {
        "id": "qOGaZ9WUEl5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "m_05KKmfwFQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備その1: 実験に使う画像データの準備"
      ],
      "metadata": {
        "id": "P-AmCU9NCRGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**注意: 以下の画像をこの実験以外の目的で使用してはいけません**"
      ],
      "metadata": {
        "id": "2qJ5Zj6r8REl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/animalphoto.pickle\n",
        "with open('animalphoto.pickle', 'rb') as f:\n",
        "    hoge = pickle.load(f)\n",
        "\n",
        "imgList = []\n",
        "for d in hoge:\n",
        "    img = Image.frombytes(**d)\n",
        "    imgList.append(img)\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Io3_Xdj5NMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備その2: クラスの番号とクラスラベルの対応表の作成"
      ],
      "metadata": {
        "id": "dwjnxlnZqkSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageNet クラスラベルを表すJSONファイルを入手\n",
        "!wget -nc https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
        "class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
        "\n",
        "K = len(class_index)\n",
        "labels = {}\n",
        "for ik, key in enumerate(class_index.keys()):\n",
        "    labels[ik] = f'{class_index[key][0]} {class_index[key][1]}'\n",
        "    if 276 <= ik < 300: \n",
        "        print(ik, labels[ik])"
      ],
      "metadata": {
        "id": "-5nFrG_ywpOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の出力は，1000クラスのうちの一部のものの名前を表します．「ネコ」みたいなものも1クラスではなく，281番 'tabby'（ぶち柄の猫），282番 'tiger_cat'（トラ縞の猫）等々のように分かれています．"
      ],
      "metadata": {
        "id": "goVX8Ln9CZ-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備3: 学習済みのニューラルネットワークのパラメータを入手\n",
        "\n",
        "規模の大きいネットワークでパラメータがたくさんありますので，読み込みに少し時間がかかります．"
      ],
      "metadata": {
        "id": "v0srx3ogtOaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.eval()\n",
        "print(vgg16)"
      ],
      "metadata": {
        "id": "uLg8zK7HyDKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルを実行すると，次のことが行われます．\n",
        "1. VGG16のネットワークモデルを作成する．\n",
        "1. ImageNetで学習済みのパラメータの値を読み込んでこのネットワークのパラメータに設定する．\n",
        "1. ネットワークモデルの構造を表示する．"
      ],
      "metadata": {
        "id": "g-V8tZ5Atyqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで用いている VGG16 というネットワークモデルは，イギリスオックスフォード大学の [Visual Geometry Group(VGG)](https://www.robots.ox.ac.uk/~vgg/) という研究グループが作った VGG-net というニューラルネットワークモデルのうちの，層が16層あるものです．\n",
        "VGG-net は，2014年に行われた [ILSVRC2014](https://www.image-net.org/challenges/LSVRC/2014/) という画像識別のコンペティションで世界第2位となったニューラルネットワークモデルです．\n",
        "ILSVRC2014では，[ImageNet](https://www.image-net.org/) という大規模な画像データセットの中から選ばれた 1000 種類の物体の画像約120万枚を学習データとしていました．\n",
        "\n",
        "画像を扱うニューラルネットでは，**畳み込み層**(convolutional layer)という特別な構造がよく用いられます．\n",
        "VGG16は，畳み込み層が13層（上記の出力の `Conv2d` というのが畳み込み層），全結合層（`Linear`，階層型ニューラルネットワークとして説明したものはこれ）3層の計16層から成っています（これ以外にもいくつか特殊な層が間に挟まってます）．\n",
        "\n",
        "参考文献: [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)"
      ],
      "metadata": {
        "id": "103RZrZeu1vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備4: 画像の前処理の定義\n",
        "\n",
        "画像をネットワークに入力できる形式に加工する処理を定義しておきます．\n"
      ],
      "metadata": {
        "id": "TVwByjcG1cyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "GeUATyKI2AYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験1\n",
        "\n",
        "上記のサンプル画像たちを VGG16 で識別させてみましょう．\n"
      ],
      "metadata": {
        "id": "uyWss1-izFXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 実験1\n",
        "#@markdown 以下で 0 から 3 までの整数を選ぶと4つのサンプル画像の中から一つを選ぶことができます．\n",
        "i = 0 #@param [0, 1, 2, 3] {type: 'raw'}\n",
        "img = imgList[i]\n",
        "\n",
        "# 画像を表示\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(imgList[i]), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "9pp3WWir8sLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の画像の下の出力は，1000個のクラスの中で，ネットワークの出力の値が大きかったもの上位5位までの，出力の値とクラス名を表します．\n",
        "ネットワークの出力層の活性化関数は softmax ですので，出力の値は0から1でかつ1000子の出力の値すべての和が 1 となっています（一般のロジスティック回帰モデルの説明参照）．\n",
        "これらの値は，そのクラスと判定することの「確信度」と解釈できます．"
      ],
      "metadata": {
        "id": "-dKliElj-rnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験2\n",
        "\n",
        "自分で用意した画像でも実験してみましょう．\n",
        "\n",
        "- 上記では動物の例ばかりですが，1000のクラスの中にはそれ以外にも様々なものがあります（人間のクラスはありません）\n",
        "- 面白い／不思議な結果が得られたら takataka に見せてくれると喜びます\n",
        "\n"
      ],
      "metadata": {
        "id": "Ss4c8IAe_9Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) まずは，ウェブ等で適当な画像を探して，この Colab notebook を実行しているコンピュータへ保存しましょう．ファイル名が長かったり日本語を含んでいる場合は，短い名前に変更しておくのがよいです．\n",
        "\n",
        "(2) 以下のセルを実行して，ファイルをアップロードします．"
      ],
      "metadata": {
        "id": "Sii3vXZ8AU2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab へファイルをアップロード\n",
        "try:\n",
        "    from google.colab import files\n",
        "    rv = files.upload()\n",
        "except:\n",
        "    print('このコードは Colab 以外の環境では実行できないよ．')"
      ],
      "metadata": {
        "id": "o83_b8kY9_Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 以下のセルの1行目のファイル名を上記でアップロードしたものに変えて実行しましょう．アルファベット大文字小文字の区別もありますので注意．うまくいけば画像が表示されるはずです．"
      ],
      "metadata": {
        "id": "PHZCqDSHBiG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myimg = Image.open('hoge.jpg') # ファイル名を変更しましょう\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(myimg)\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F72S_3eO9Ask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) 以下のセルを実行すれば結果が表示されます．"
      ],
      "metadata": {
        "id": "YGckmXO7Bzs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(myimg), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "u8vrSrciBbgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e94_duuoCEcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ex06noteC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}